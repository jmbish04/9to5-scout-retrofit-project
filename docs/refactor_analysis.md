# Refactor Analysis: src/index.ts Modularization

The table below maps every executable code block, class, and interface from the original `src/index.ts` (commit 717d6af, main branch) to its new modular location in the refactored codebase. Each row includes the exact source lines, the new module and lines, and a parity assessment.

| main branch code block | PR matching code block [in new modular path] | ✅ or ❌ w/ instructions on how to reach parity with codeblock in main branch |
| :--- | :--- | :--- |
| `typescript<br>src/index.ts (717d6af), lines 23-24<br><br>// Placeholder types for Durable Objects until full implementations are added.<br>type DurableObjectState = any;<br>` | `typescript<br>src/lib/durable-objects/site-crawler.ts, lines 1-6<br><br>import type { Env } from '../env';<br><br>type DurableObjectState = any;<br><br>export class SiteCrawler {<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 52-97<br><br>/**<br> * Parses a URL pathname against a routing pattern to extract path parameters.<br> * * This utility function is essential for robust API routing within the Worker, allowing<br> * agents and developers to reliably target resources using dynamic IDs (e.g., `/api/jobs/123`).<br> * * @param {string} pathname - The actual URL pathname (e.g., '/api/jobs/123').<br> * @param {string} pattern - The path pattern containing parameter placeholders (e.g., '/api/jobs/:id').<br> * @returns {Record<string, string> | null} An object mapping parameter names to their values, or null if the path doesn't match the pattern.<br> * * @example<br> * // Agent Use Case: Extracting job ID for /api/jobs/:id<br> * const params = parsePathParams('/api/jobs/123', '/api/jobs/:id');<br> * // params: { id: '123' }<br> * * @example<br> * // Agent Use Case: Extracting nested parameters<br> * const params = parsePathParams('/api/users/456/posts/789', '/api/users/:userId/posts/:postId');<br> * // params: { userId: '456', postId: '789' }<br> */<br>function parsePathParams(pathname: string, pattern: string): Record<string, string> | null {<br>  const pathParts = pathname.split('/').filter(Boolean);<br>  const patternParts = pattern.split('/').filter(Boolean);<br><br>  if (pathParts.length !== patternParts.length) {<br>    return null;<br>  }<br><br>  const params: Record<string, string> = {};<br><br>  for (let i = 0; i < patternParts.length; i++) {<br>    const patternPart = patternParts[i];<br>    const pathPart = pathParts[i];<br><br>    if (!patternPart || !pathPart) {<br>      return null;<br>    }<br><br>    if (patternPart.startsWith(':')) {<br>      // Parameter segment<br>      const paramName = patternPart.slice(1);<br>      params[paramName] = decodeURIComponent(pathPart);<br>    } else if (patternPart !== pathPart) {<br>      // Literal segment doesn't match<br>      return null;<br>    }<br>  }<br><br>  return params;<br>}<br>` | `typescript<br>src/lib/routing.ts, lines 1-34<br><br>/**<br> * Parses a URL pathname against a routing pattern to extract path parameters.<br> *<br> * @param pathname - The actual URL pathname (e.g., '/api/jobs/123').<br> * @param pattern - The path pattern containing parameter placeholders (e.g., '/api/jobs/:id').<br> * @returns An object mapping parameter names to their values, or null if the path doesn't match the pattern.<br> */<br>export function parsePathParams(pathname: string, pattern: string): Record<string, string> | null {<br>  const pathParts = pathname.split('/').filter(Boolean);<br>  const patternParts = pattern.split('/').filter(Boolean);<br><br>  if (pathParts.length !== patternParts.length) {<br>    return null;<br>  }<br><br>  const params: Record<string, string> = {};<br><br>  for (let i = 0; i < patternParts.length; i++) {<br>    const patternPart = patternParts[i];<br>    const pathPart = pathParts[i];<br><br>    if (!patternPart || !pathPart) {<br>      return null;<br>    }<br><br>    if (patternPart.startsWith(':')) {<br>      params[patternPart.slice(1)] = decodeURIComponent(pathPart);<br>    } else if (patternPart !== pathPart) {<br>      return null;<br>    }<br>  }<br><br>  return params;<br>}<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 99-164<br><br>interface CoverLetterRequestBody {<br>  job_title: string;<br>  company_name: string;<br>  hiring_manager_name?: string;<br>  job_description_text: string;<br>  candidate_career_summary: string;<br>}<br><br>interface CoverLetterContent {<br>  salutation: string;<br>  opening_paragraph: string;<br>  body_paragraph_1: string;<br>  body_paragraph_2: string;<br>  closing_paragraph: string;<br>}<br><br>interface ResumeRequestBody {<br>  job_title: string;<br>  company_name: string;<br>  job_description_text: string;<br>  candidate_career_summary: string;<br>}<br><br>interface ResumeContent {<br>  summary: string;<br>  experience_bullets: string[];<br>  skills: string[];<br>}<br>` | `typescript<br>src/routes/ai-documents.ts, lines 1-29<br><br>import type { Env } from '../lib/env';<br><br>interface CoverLetterRequestBody {<br>  job_title: string;<br>  company_name: string;<br>  hiring_manager_name?: string;<br>  job_description_text: string;<br>  candidate_career_summary: string;<br>}<br><br>interface CoverLetterContent {<br>  salutation: string;<br>  opening_paragraph: string;<br>  body_paragraph_1: string;<br>  body_paragraph_2: string;<br>  closing_paragraph: string;<br>}<br><br>interface ResumeRequestBody {<br>  job_title: string;<br>  company_name: string;<br>  job_description_text: string;<br>  candidate_career_summary: string;<br>}<br><br>interface ResumeContent {<br>  summary: string;<br>  experience_bullets: string[];<br>  skills: string[];<br>}<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 166-211<br><br>export interface Env {<br>  AI: any;<br>  DB: any;<br>  KV: any;<br>  R2: any;<br>  VECTORIZE_INDEX: any;<br>  MYBROWSER: any;<br>  ASSETS: any;<br>  API_AUTH_TOKEN: string;<br>  BROWSER_RENDERING_TOKEN: string;<br>  SLACK_WEBHOOK_URL: string;<br>  SMTP_ENDPOINT: string;<br>  SMTP_USERNAME: string;<br>  SMTP_PASSWORD: string;<br>  SITE_CRAWLER: any;<br>  JOB_MONITOR: any;<br>  DISCOVERY_WORKFLOW: any;<br>  JOB_MONITOR_WORKFLOW: any;<br>  CHANGE_ANALYSIS_WORKFLOW: any;<br>  SCRAPE_SOCKET: any;<br>}<br>` | `typescript<br>src/lib/env.ts, lines 1-21<br><br>export interface Env {<br>  AI: any;<br>  DB: any;<br>  KV: any;<br>  R2: any;<br>  VECTORIZE_INDEX: any;<br>  MYBROWSER: any;<br>  ASSETS: any;<br>  API_AUTH_TOKEN: string;<br>  BROWSER_RENDERING_TOKEN: string;<br>  SLACK_WEBHOOK_URL: string;<br>  SMTP_ENDPOINT: string;<br>  SMTP_USERNAME: string;<br>  SMTP_PASSWORD: string;<br>  SITE_CRAWLER: any;<br>  JOB_MONITOR: any;<br>  DISCOVERY_WORKFLOW: any;<br>  JOB_MONITOR_WORKFLOW: any;<br>  CHANGE_ANALYSIS_WORKFLOW: any;<br>  SCRAPE_SOCKET: any;<br>}<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 213-377<br><br>export class SiteCrawler {<br>  private state: DurableObjectState;<br>  private env: Env;<br><br>  constructor(state: DurableObjectState, env: Env) {<br>    this.state = state;<br>    this.env = env;<br>  }<br><br>  async fetch(req: Request): Promise<Response> {<br>    const url = new URL(req.url);<br>    const path = url.pathname;<br><br>    try {<br>      if (path === '/start-discovery' && req.method === 'POST') {<br>        return await this.startDiscovery(req);<br>      }<br><br>      if (path === '/status' && req.method === 'GET') {<br>        return await this.getStatus();<br>      }<br><br>      if (path === '/crawl-urls' && req.method === 'POST') {<br>        return await this.crawlUrls(req);<br>      }<br><br>      return new Response('Not Found', { status: 404 });<br>    } catch (error) {<br>      console.error('SiteCrawler error:', error);<br>      return new Response(JSON.stringify({ error: 'Internal server error' }), {<br>        status: 500,<br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    }<br>  }<br><br>  private async startDiscovery(req: Request): Promise<Response> {<br>    const { site_id, base_url, search_terms } = await req.json() as {<br>      site_id: string;<br>      base_url: string;<br>      search_terms?: string[];<br>    };<br><br>    await this.state.storage.put('current_site_id', site_id);<br>    await this.state.storage.put('base_url', base_url);<br>    await this.state.storage.put('last_activity', new Date().toISOString());<br>    await this.state.storage.put('status', 'discovering');<br><br>    const { discoverJobUrls } = await import('./lib/crawl');<br>    const urls = await discoverJobUrls(base_url, search_terms || []);<br><br>    await this.state.storage.put('discovered_urls', urls);<br>    await this.state.storage.put('total_discovered', urls.length);<br>    await this.state.storage.put('crawled_count', 0);<br><br>    return new Response(JSON.stringify({<br>      site_id,<br>      discovered_count: urls.length,<br>      status: 'discovery_complete',<br>    }), {<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br><br>  private async crawlUrls(req: Request): Promise<Response> {<br>    const { batch_size = 5 } = await req.json() as { batch_size?: number };<br><br>    const urls = await this.state.storage.get('discovered_urls') as string[] || [];<br>    const crawledCount = await this.state.storage.get('crawled_count') as number || 0;<br>    const siteId = await this.state.storage.get('current_site_id') as string;<br><br>    if (crawledCount >= urls.length) {<br>      await this.state.storage.put('status', 'completed');<br>      return new Response(JSON.stringify({ status: 'completed', message: 'All URLs crawled' }), {<br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    }<br><br>    const batchUrls = urls.slice(crawledCount, crawledCount + batch_size);<br><br>    const { crawlJobs } = await import('./lib/crawl');<br>    const jobs = await crawlJobs(this.env, batchUrls, siteId);<br><br>    const newCrawledCount = crawledCount + batchUrls.length;<br>    await this.state.storage.put('crawled_count', newCrawledCount);<br>    await this.state.storage.put('last_activity', new Date().toISOString());<br><br>    const isComplete = newCrawledCount >= urls.length;<br>    if (isComplete) {<br>      await this.state.storage.put('status', 'completed');<br>    }<br><br>    return new Response(JSON.stringify({<br>      crawled_in_batch: jobs.length,<br>      total_crawled: newCrawledCount,<br>      total_discovered: urls.length,<br>      status: isComplete ? 'completed' : 'crawling',<br>    }), {<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br><br>  private async getStatus(): Promise<Response> {<br>    const status = await this.state.storage.get('status') || 'idle';<br>    const totalDiscovered = await this.state.storage.get('total_discovered') || 0;<br>    const crawledCount = await this.state.storage.get('crawled_count') || 0;<br>    const lastActivity = await this.state.storage.get('last_activity');<br>    const siteId = await this.state.storage.get('current_site_id');<br><br>    return new Response(JSON.stringify({<br>      site_id: siteId,<br>      status,<br>      total_discovered: totalDiscovered,<br>      crawled_count: crawledCount,<br>      last_activity: lastActivity,<br>    }), {<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br>}<br>` | `typescript<br>src/lib/durable-objects/site-crawler.ts, lines 5-124<br><br>export class SiteCrawler {<br>  private state: DurableObjectState;<br>  private env: Env;<br><br>  constructor(state: DurableObjectState, env: Env) {<br>    this.state = state;<br>    this.env = env;<br>  }<br><br>  async fetch(req: Request): Promise<Response> {<br>    const url = new URL(req.url);<br>    const path = url.pathname;<br><br>    try {<br>      if (path === '/start-discovery' && req.method === 'POST') {<br>        return await this.startDiscovery(req);<br>      }<br><br>      if (path === '/status' && req.method === 'GET') {<br>        return await this.getStatus();<br>      }<br><br>      if (path === '/crawl-urls' && req.method === 'POST') {<br>        return await this.crawlUrls(req);<br>      }<br><br>      return new Response('Not Found', { status: 404 });<br>    } catch (error) {<br>      console.error('SiteCrawler error:', error);<br>      return new Response(JSON.stringify({ error: 'Internal server error' }), {<br>        status: 500,<br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    }<br>  }<br><br>  private async startDiscovery(req: Request): Promise<Response> {<br>    const { site_id, base_url, search_terms } = await req.json() as {<br>      site_id: string;<br>      base_url: string;<br>      search_terms?: string[];<br>    };<br><br>    await this.state.storage.put('current_site_id', site_id);<br>    await this.state.storage.put('base_url', base_url);<br>    await this.state.storage.put('last_activity', new Date().toISOString());<br>    await this.state.storage.put('status', 'discovering');<br><br>    const { discoverJobUrls } = await import('../crawl');<br>    const urls = await discoverJobUrls(base_url, search_terms || []);<br><br>    await this.state.storage.put('discovered_urls', urls);<br>    await this.state.storage.put('total_discovered', urls.length);<br>    await this.state.storage.put('crawled_count', 0);<br><br>    return new Response(JSON.stringify({<br>      site_id,<br>      discovered_count: urls.length,<br>      status: 'discovery_complete',<br>    }), {<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br><br>  private async crawlUrls(req: Request): Promise<Response> {<br>    const { batch_size = 5 } = await req.json() as { batch_size?: number };<br><br>    const urls = await this.state.storage.get('discovered_urls') as string[] || [];<br>    const crawledCount = await this.state.storage.get('crawled_count') as number || 0;<br>    const siteId = await this.state.storage.get('current_site_id') as string;<br><br>    if (crawledCount >= urls.length) {<br>      await this.state.storage.put('status', 'completed');<br>      return new Response(JSON.stringify({ status: 'completed', message: 'All URLs crawled' }), {<br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    }<br><br>    const batchUrls = urls.slice(crawledCount, crawledCount + batch_size);<br><br>    const { crawlJobs } = await import('../crawl');<br>    const jobs = await crawlJobs(this.env, batchUrls, siteId);<br><br>    const newCrawledCount = crawledCount + batchUrls.length;<br>    await this.state.storage.put('crawled_count', newCrawledCount);<br>    await this.state.storage.put('last_activity', new Date().toISOString());<br><br>    const isComplete = newCrawledCount >= urls.length;<br>    if (isComplete) {<br>      await this.state.storage.put('status', 'completed');<br>    }<br><br>    return new Response(JSON.stringify({<br>      crawled_in_batch: jobs.length,<br>      total_crawled: newCrawledCount,<br>      total_discovered: urls.length,<br>      status: isComplete ? 'completed' : 'crawling',<br>    }), {<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br><br>  private async getStatus(): Promise<Response> {<br>    const status = await this.state.storage.get('status') || 'idle';<br>    const totalDiscovered = await this.state.storage.get('total_discovered') || 0;<br>    const crawledCount = await this.state.storage.get('crawled_count') || 0;<br>    const lastActivity = await this.state.storage.get('last_activity');<br>    const siteId = await this.state.storage.get('current_site_id');<br><br>    return new Response(JSON.stringify({<br>      site_id: siteId,<br>      status,<br>      total_discovered: totalDiscovered,<br>      crawled_count: crawledCount,<br>      last_activity: lastActivity,<br>    }), {<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br>}<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 213-237<br><br>export class SiteCrawler {<br>  private state: DurableObjectState;<br>  private env: Env;<br><br>  constructor(state: DurableObjectState, env: Env) {<br>    this.state = state;<br>    this.env = env;<br>  }<br>` | `typescript<br>src/lib/durable-objects/site-crawler.ts, lines 5-13<br><br>export class SiteCrawler {<br>  private state: DurableObjectState;<br>  private env: Env;<br><br>  constructor(state: DurableObjectState, env: Env) {<br>    this.state = state;<br>    this.env = env;<br>  }<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 239-269<br><br>async fetch(req: Request): Promise<Response> {<br>  const url = new URL(req.url);<br>  const path = url.pathname;<br><br>  try {<br>    if (path === '/start-discovery' && req.method === 'POST') {<br>      return await this.startDiscovery(req);<br>    }<br><br>    if (path === '/status' && req.method === 'GET') {<br>      return await this.getStatus();<br>    }<br><br>    if (path === '/crawl-urls' && req.method === 'POST') {<br>      return await this.crawlUrls(req);<br>    }<br><br>    return new Response('Not Found', { status: 404 });<br>  } catch (error) {<br>    console.error('SiteCrawler error:', error);<br>    return new Response(JSON.stringify({ error: 'Internal server error' }), {<br>      status: 500,<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br>}<br>` | `typescript<br>src/lib/durable-objects/site-crawler.ts, lines 14-38<br><br>async fetch(req: Request): Promise<Response> {<br>  const url = new URL(req.url);<br>  const path = url.pathname;<br><br>  try {<br>    if (path === '/start-discovery' && req.method === 'POST') {<br>      return await this.startDiscovery(req);<br>    }<br><br>    if (path === '/status' && req.method === 'GET') {<br>      return await this.getStatus();<br>    }<br><br>    if (path === '/crawl-urls' && req.method === 'POST') {<br>      return await this.crawlUrls(req);<br>    }<br><br>    return new Response('Not Found', { status: 404 });<br>  } catch (error) {<br>    console.error('SiteCrawler error:', error);<br>    return new Response(JSON.stringify({ error: 'Internal server error' }), {<br>      status: 500,<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br>}<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 271-306<br><br>private async startDiscovery(req: Request): Promise<Response> {<br>  const { site_id, base_url, search_terms } = await req.json() as {<br>    site_id: string;<br>    base_url: string;<br>    search_terms?: string[];<br>  };<br><br>  await this.state.storage.put('current_site_id', site_id);<br>  await this.state.storage.put('base_url', base_url);<br>  await this.state.storage.put('last_activity', new Date().toISOString());<br>  await this.state.storage.put('status', 'discovering');<br><br>  const { discoverJobUrls } = await import('./lib/crawl');<br>  const urls = await discoverJobUrls(base_url, search_terms || []);<br><br>  await this.state.storage.put('discovered_urls', urls);<br>  await this.state.storage.put('total_discovered', urls.length);<br>  await this.state.storage.put('crawled_count', 0);<br><br>  return new Response(JSON.stringify({<br>    site_id,<br>    discovered_count: urls.length,<br>    status: 'discovery_complete',<br>  }), {<br>    headers: { 'Content-Type': 'application/json' },<br>  });<br>}<br>` | `typescript<br>src/lib/durable-objects/site-crawler.ts, lines 40-67<br><br>private async startDiscovery(req: Request): Promise<Response> {<br>  const { site_id, base_url, search_terms } = await req.json() as {<br>    site_id: string;<br>    base_url: string;<br>    search_terms?: string[];<br>  };<br><br>  await this.state.storage.put('current_site_id', site_id);<br>  await this.state.storage.put('base_url', base_url);<br>  await this.state.storage.put('last_activity', new Date().toISOString());<br>  await this.state.storage.put('status', 'discovering');<br><br>  const { discoverJobUrls } = await import('../crawl');<br>  const urls = await discoverJobUrls(base_url, search_terms || []);<br><br>  await this.state.storage.put('discovered_urls', urls);<br>  await this.state.storage.put('total_discovered', urls.length);<br>  await this.state.storage.put('crawled_count', 0);<br><br>  return new Response(JSON.stringify({<br>    site_id,<br>    discovered_count: urls.length,<br>    status: 'discovery_complete',<br>  }), {<br>    headers: { 'Content-Type': 'application/json' },<br>  });<br>}<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 315-352<br><br>private async crawlUrls(req: Request): Promise<Response> {<br>  const { batch_size = 5 } = await req.json() as { batch_size?: number };<br><br>  const urls = await this.state.storage.get('discovered_urls') as string[] || [];<br>  const crawledCount = await this.state.storage.get('crawled_count') as number || 0;<br>  const siteId = await this.state.storage.get('current_site_id') as string;<br><br>  if (crawledCount >= urls.length) {<br>    await this.state.storage.put('status', 'completed');<br>    return new Response(JSON.stringify({ status: 'completed', message: 'All URLs crawled' }), {<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br><br>  const batchUrls = urls.slice(crawledCount, crawledCount + batch_size);<br><br>  const { crawlJobs } = await import('./lib/crawl');<br>  const jobs = await crawlJobs(this.env, batchUrls, siteId);<br><br>  const newCrawledCount = crawledCount + batchUrls.length;<br>  await this.state.storage.put('crawled_count', newCrawledCount);<br>  await this.state.storage.put('last_activity', new Date().toISOString());<br><br>  const isComplete = newCrawledCount >= urls.length;<br>  if (isComplete) {<br>    await this.state.storage.put('status', 'completed');<br>  }<br><br>  return new Response(JSON.stringify({<br>    crawled_in_batch: jobs.length,<br>    total_crawled: newCrawledCount,<br>    total_discovered: urls.length,<br>    status: isComplete ? 'completed' : 'crawling',<br>  }), {<br>    headers: { 'Content-Type': 'application/json' },<br>  });<br>}<br>` | `typescript<br>src/lib/durable-objects/site-crawler.ts, lines 69-105<br><br>private async crawlUrls(req: Request): Promise<Response> {<br>  const { batch_size = 5 } = await req.json() as { batch_size?: number };<br><br>  const urls = await this.state.storage.get('discovered_urls') as string[] || [];<br>  const crawledCount = await this.state.storage.get('crawled_count') as number || 0;<br>  const siteId = await this.state.storage.get('current_site_id') as string;<br><br>  if (crawledCount >= urls.length) {<br>    await this.state.storage.put('status', 'completed');<br>    return new Response(JSON.stringify({ status: 'completed', message: 'All URLs crawled' }), {<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br><br>  const batchUrls = urls.slice(crawledCount, crawledCount + batch_size);<br><br>  const { crawlJobs } = await import('../crawl');<br>  const jobs = await crawlJobs(this.env, batchUrls, siteId);<br><br>  const newCrawledCount = crawledCount + batchUrls.length;<br>  await this.state.storage.put('crawled_count', newCrawledCount);<br>  await this.state.storage.put('last_activity', new Date().toISOString());<br><br>  const isComplete = newCrawledCount >= urls.length;<br>  if (isComplete) {<br>    await this.state.storage.put('status', 'completed');<br>  }<br><br>  return new Response(JSON.stringify({<br>    crawled_in_batch: jobs.length,<br>    total_crawled: newCrawledCount,<br>    total_discovered: urls.length,<br>    status: isComplete ? 'completed' : 'crawling',<br>  }), {<br>    headers: { 'Content-Type': 'application/json' },<br>  });<br>}<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 360-376<br><br>private async getStatus(): Promise<Response> {<br>  const status = await this.state.storage.get('status') || 'idle';<br>  const totalDiscovered = await this.state.storage.get('total_discovered') || 0;<br>  const crawledCount = await this.state.storage.get('crawled_count') || 0;<br>  const lastActivity = await this.state.storage.get('last_activity');<br>  const siteId = await this.state.storage.get('current_site_id');<br><br>  return new Response(JSON.stringify({<br>    site_id: siteId,<br>    status,<br>    total_discovered: totalDiscovered,<br>    crawled_count: crawledCount,<br>    last_activity: lastActivity,<br>  }), {<br>    headers: { 'Content-Type': 'application/json' },<br>  });<br>}<br>` | `typescript<br>src/lib/durable-objects/site-crawler.ts, lines 107-123<br><br>private async getStatus(): Promise<Response> {<br>  const status = await this.state.storage.get('status') || 'idle';<br>  const totalDiscovered = await this.state.storage.get('total_discovered') || 0;<br>  const crawledCount = await this.state.storage.get('crawled_count') || 0;<br>  const lastActivity = await this.state.storage.get('last_activity');<br>  const siteId = await this.state.storage.get('current_site_id');<br><br>  return new Response(JSON.stringify({<br>    site_id: siteId,<br>    status,<br>    total_discovered: totalDiscovered,<br>    crawled_count: crawledCount,<br>    last_activity: lastActivity,<br>  }), {<br>    headers: { 'Content-Type': 'application/json' },<br>  });<br>}<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 391-403<br><br>export class JobMonitor {<br>  private state: DurableObjectState;<br>  private env: Env;<br><br>  constructor(state: DurableObjectState, env: Env) {<br>    this.state = state;<br>    this.env = env;<br>  }<br>` | `typescript<br>src/lib/durable-objects/job-monitor.ts, lines 5-12<br><br>export class JobMonitor {<br>  private state: DurableObjectState;<br>  private env: Env;<br><br>  constructor(state: DurableObjectState, env: Env) {<br>    this.state = state;<br>    this.env = env;<br>  }<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 410-435<br><br>async fetch(req: Request): Promise<Response> {<br>  const url = new URL(req.url);<br>  const path = url.pathname;<br><br>  try {<br>    if (path === '/monitor-job' && req.method === 'POST') {<br>      return await this.monitorJob(req);<br>    }<br><br>    if (path === '/check-job' && req.method === 'POST') {<br>      return await this.checkJob(req);<br>    }<br><br>    if (path === '/status' && req.method === 'GET') {<br>      return await this.getStatus();<br>    }<br><br>    return new Response('Not Found', { status: 404 });<br>  } catch (error) {<br>    console.error('JobMonitor error:', error);<br>    return new Response(JSON.stringify({ error: 'Internal server error' }), {<br>      status: 500,<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br>}<br>` | `typescript<br>src/lib/durable-objects/job-monitor.ts, lines 14-38<br><br>async fetch(req: Request): Promise<Response> {<br>  const url = new URL(req.url);<br>  const path = url.pathname;<br><br>  try {<br>    if (path === '/monitor-job' && req.method === 'POST') {<br>      return await this.monitorJob(req);<br>    }<br><br>    if (path === '/check-job' && req.method === 'POST') {<br>      return await this.checkJob(req);<br>    }<br><br>    if (path === '/status' && req.method === 'GET') {<br>      return await this.getStatus();<br>    }<br><br>    return new Response('Not Found', { status: 404 });<br>  } catch (error) {<br>    console.error('JobMonitor error:', error);<br>    return new Response(JSON.stringify({ error: 'Internal server error' }), {<br>      status: 500,<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br>}<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 443-468<br><br>private async monitorJob(req: Request): Promise<Response> {<br>  const { job_id, url, check_interval_hours = 24 } = await req.json() as {<br>    job_id: string;<br>    url: string;<br>    check_interval_hours?: number;<br>  };<br><br>  await this.state.storage.put('job_id', job_id);<br>  await this.state.storage.put('job_url', url);<br>  await this.state.storage.put('check_interval_hours', check_interval_hours);<br>  await this.state.storage.put('last_check', new Date().toISOString());<br>  await this.state.storage.put('status', 'monitoring');<br><br>  const nextCheck = new Date(Date.now() + check_interval_hours * 60 * 60 * 1000);<br>  await this.state.storage.setAlarm(nextCheck);<br><br>  return new Response(JSON.stringify({<br>    job_id,<br>    status: 'monitoring_started',<br>    next_check: nextCheck.toISOString(),<br>  }), {<br>    headers: { 'Content-Type': 'application/json' },<br>  });<br>}<br>` | `typescript<br>src/lib/durable-objects/job-monitor.ts, lines 41-63<br><br>private async monitorJob(req: Request): Promise<Response> {<br>  const { job_id, url, check_interval_hours = 24 } = await req.json() as {<br>    job_id: string;<br>    url: string;<br>    check_interval_hours?: number;<br>  };<br><br>  await this.state.storage.put('job_id', job_id);<br>  await this.state.storage.put('job_url', url);<br>  await this.state.storage.put('check_interval_hours', check_interval_hours);<br>  await this.state.storage.put('last_check', new Date().toISOString());<br>  await this.state.storage.put('status', 'monitoring');<br><br>  const nextCheck = new Date(Date.now() + check_interval_hours * 60 * 60 * 1000);<br>  await this.state.storage.setAlarm(nextCheck);<br><br>  return new Response(JSON.stringify({<br>    job_id,<br>    status: 'monitoring_started',<br>    next_check: nextCheck.toISOString(),<br>  }), {<br>    headers: { 'Content-Type': 'application/json' },<br>  });<br>}<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 477-526<br><br>private async checkJob(req: Request): Promise<Response> {<br>  const jobUrl = await this.state.storage.get('job_url') as string;<br>  const jobId = await this.state.storage.get('job_id') as string;<br><br>  if (!jobUrl || !jobId) {<br>    return new Response(JSON.stringify({ error: 'No job configured for monitoring' }), {<br>      status: 400,<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br><br>  const { crawlJob } = await import('./lib/crawl');<br>  const currentJob = await crawlJob(this.env, jobUrl);<br><br>  const lastCheck = new Date().toISOString();<br>  await this.state.storage.put('last_check', lastCheck);<br><br>  if (!currentJob) {<br>    await this.state.storage.put('status', 'job_not_found');<br><br>    await this.env.DB.prepare('UPDATE jobs SET status = ?, closed_at = ? WHERE id = ?')<br>      .bind('closed', lastCheck, jobId)<br>      .run();<br><br>    return new Response(JSON.stringify({<br>      job_id: jobId,<br>      status: 'job_not_found',<br>      last_check: lastCheck,<br>    }), {<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br><br>  await this.env.DB.prepare('UPDATE jobs SET last_seen_open_at = ?, last_crawled_at = ? WHERE id = ?')<br>    .bind(lastCheck, lastCheck, jobId)<br>    .run();<br><br>  return new Response(JSON.stringify({<br>    job_id: jobId,<br>    status: 'job_active',<br>    last_check: lastCheck,<br>    title: currentJob.title,<br>    company: currentJob.company,<br>  }), {<br>    headers: { 'Content-Type': 'application/json' },<br>  });<br>}<br>` | `typescript<br>src/lib/durable-objects/job-monitor.ts, lines 66-112<br><br>private async checkJob(req: Request): Promise<Response> {<br>  const jobUrl = await this.state.storage.get('job_url') as string;<br>  const jobId = await this.state.storage.get('job_id') as string;<br><br>  if (!jobUrl || !jobId) {<br>    return new Response(JSON.stringify({ error: 'No job configured for monitoring' }), {<br>      status: 400,<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br><br>  const { crawlJob } = await import('../crawl');<br>  const currentJob = await crawlJob(this.env, jobUrl);<br><br>  const lastCheck = new Date().toISOString();<br>  await this.state.storage.put('last_check', lastCheck);<br><br>  if (!currentJob) {<br>    await this.state.storage.put('status', 'job_not_found');<br><br>    await this.env.DB.prepare('UPDATE jobs SET status = ?, closed_at = ? WHERE id = ?')<br>      .bind('closed', lastCheck, jobId)<br>      .run();<br><br>    return new Response(JSON.stringify({<br>      job_id: jobId,<br>      status: 'job_not_found',<br>      last_check: lastCheck,<br>    }), {<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br><br>  await this.env.DB.prepare('UPDATE jobs SET last_seen_open_at = ?, last_crawled_at = ? WHERE id = ?')<br>    .bind(lastCheck, lastCheck, jobId)<br>    .run();<br><br>  return new Response(JSON.stringify({<br>    job_id: jobId,<br>    status: 'job_active',<br>    last_check: lastCheck,<br>    title: currentJob.title,<br>    company: currentJob.company,<br>    location: currentJob.location,<br>  }), {<br>    headers: { 'Content-Type': 'application/json' },<br>  });<br>}<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 534-547<br><br>private async getStatus(): Promise<Response> {<br>  const jobId = await this.state.storage.get('job_id');<br>  const status = await this.state.storage.get('status') || 'idle';<br>  const lastCheck = await this.state.storage.get('last_check');<br>  const checkInterval = await this.state.storage.get('check_interval_hours') || 24;<br><br>  return new Response(JSON.stringify({<br>    job_id: jobId,<br>    status,<br>    last_check: lastCheck,<br>    check_interval_hours: checkInterval,<br>  }), {<br>    headers: { 'Content-Type': 'application/json' },<br>  });<br>}<br>` | `typescript<br>src/lib/durable-objects/job-monitor.ts, lines 115-128<br><br>private async getStatus(): Promise<Response> {<br>  const jobId = await this.state.storage.get('job_id');<br>  const status = await this.state.storage.get('status') || 'idle';<br>  const lastCheck = await this.state.storage.get('last_check');<br>  const checkInterval = await this.state.storage.get('check_interval_hours') || 24;<br><br>  return new Response(JSON.stringify({<br>    job_id: jobId,<br>    status,<br>    last_check: lastCheck,<br>    check_interval_hours: checkInterval,<br>  }), {<br>    headers: { 'Content-Type': 'application/json' },<br>  });<br>}<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 555-569<br><br>async alarm(): Promise<void> {<br>  try {<br>    await this.checkJob(new Request('http://localhost/check-job', { method: 'POST' }));<br><br>    const status = await this.state.storage.get('status');<br>    if (status === 'monitoring' || status === 'job_active') {<br>      const checkInterval = await this.state.storage.get('check_interval_hours') as number || 24;<br>      const nextCheck = new Date(Date.now() + checkInterval * 60 * 60 * 1000);<br>      await this.state.storage.setAlarm(nextCheck);<br>    }<br>  } catch (error) {<br>    console.error('JobMonitor alarm error:', error);<br>  }<br>}<br>` | `typescript<br>src/lib/durable-objects/job-monitor.ts, lines 131-148<br><br>async alarm(): Promise<void> {<br>  try {<br>    const status = await this.state.storage.get('status');<br>    if (status !== 'monitoring' && status !== 'job_active') {<br>      return;<br>    }<br><br>    await this.checkJob(new Request('http://localhost/check-job', { method: 'POST' }));<br><br>    const finalStatus = await this.state.storage.get('status');<br>    if (finalStatus === 'monitoring' || finalStatus === 'job_active') {<br>      const checkInterval = await this.state.storage.get('check_interval_hours') as number || 24;<br>      const nextCheck = new Date(Date.now() + checkInterval * 60 * 60 * 1000);<br>      await this.state.storage.setAlarm(nextCheck);<br>    }<br>  } catch (error) {<br>    console.error('JobMonitor alarm error:', error);<br>  }<br>}<br>` | ✅ (pre-check ensures idle monitors no longer trigger while preserving post-check rescheduling logic) |
| `typescript<br>src/index.ts (717d6af), lines 582-644<br><br>export class DiscoveryWorkflow {<br>  /**<br>   * Main workflow execution for job discovery.<br>   * @param {Env} env - Worker environment bindings.<br>   * @param {object} payload - Configuration for the run.<br>   * @param {string} [payload.config_id] - Optional ID of a specific configuration to run. If not provided, all active configurations are used.<br>   * @returns {Promise<any>} Summary of the discovery results.<br>   */<br>  async run(env: Env, payload: { config_id?: string }): Promise<any> {<br>    const { config_id } = payload;<br>    <br>    try {<br>      // Get search configuration<br>      const { getSearchConfigs, getSites } = await import('./lib/storage');<br>      const configs = config_id<br>        ? [(await env.DB.prepare('SELECT * FROM search_configs WHERE id = ?').bind(config_id).first())]<br>        : await getSearchConfigs(env);<br>      <br>      const sites = await getSites(env);<br>      <br>      const results = [];<br>      <br>      for (const config of configs.filter(Boolean)) {<br>        for (const site of sites) {<br>          // Create Durable Object instance for this site<br>          const crawlerId = env.SITE_CRAWLER.idFromName(\`${site.id}-${config.id}\`);<br>          const crawler = env.SITE_CRAWLER.get(crawlerId);<br>          <br>          // Start discovery<br>          const discoveryResponse = await crawler.fetch('http://localhost/start-discovery', {<br>            method: 'POST',<br>            headers: { 'Content-Type': 'application/json' },<br>            body: JSON.stringify({<br>              site_id: site.id,<br>              base_url: site.base_url,<br>              search_terms: JSON.parse(config.keywords || '[]'),<br>            }),<br>          });<br>          <br>          const discoveryResult = await discoveryResponse.json();<br>          results.push({<br>            site: site.name,<br>            config: config.name,<br>            ...discoveryResult,<br>          });<br>          <br>          // Start crawling discovered URLs<br>          if (discoveryResult.discovered_count > 0) {<br>            await crawler.fetch('http://localhost/crawl-urls', {<br>              method: 'POST',<br>              headers: { 'Content-Type': 'application/json' },<br>              body: JSON.stringify({ batch_size: 5 }),<br>            });<br>          }<br>        }<br>      }<br>      <br>      return { results, total_configs: configs.length, total_sites: sites.length };<br>    } catch (error) {<br>      console.error('Discovery workflow error:', error);<br>      throw error;<br>    }<br>  }<br>}<br>` | `typescript<br>src/lib/workflows/discovery-workflow.ts, lines 3-54<br><br>export class DiscoveryWorkflow {<br>  async run(env: Env, payload: { config_id?: string }): Promise<any> {<br>    const { config_id } = payload;<br><br>    try {<br>      const { getSearchConfigs, getSites } = await import('../storage');<br>      const configs = config_id<br>        ? [(await env.DB.prepare('SELECT * FROM search_configs WHERE id = ?').bind(config_id).first())]<br>        : await getSearchConfigs(env);<br><br>      const sites = await getSites(env);<br>      const results = [];<br><br>      for (const config of configs.filter(Boolean)) {<br>        for (const site of sites) {<br>          const crawlerId = env.SITE_CRAWLER.idFromName(\`${site.id}-${config.id}\`);<br>          const crawler = env.SITE_CRAWLER.get(crawlerId);<br><br>          const discoveryResponse = await crawler.fetch('http://localhost/start-discovery', {<br>            method: 'POST',<br>            headers: { 'Content-Type': 'application/json' },<br>            body: JSON.stringify({<br>              site_id: site.id,<br>              base_url: site.base_url,<br>              search_terms: JSON.parse(config.keywords || '[]'),<br>            }),<br>          });<br><br>          const discoveryResult = await discoveryResponse.json();<br>          results.push({<br>            site: site.name,<br>            config: config.name,<br>            ...discoveryResult,<br>          });<br><br>          if (discoveryResult.discovered_count > 0) {<br>            await crawler.fetch('http://localhost/crawl-urls', {<br>              method: 'POST',<br>              headers: { 'Content-Type': 'application/json' },<br>              body: JSON.stringify({ batch_size: 5 }),<br>            });<br>          }<br>        }<br>      }<br><br>      return { results, total_configs: configs.length, total_sites: sites.length };<br>    } catch (error) {<br>      console.error('Discovery workflow error:', error);<br>      throw error;<br>    }<br>  }<br>}<br>` | ✅ |\n| `typescript<br>src/index.ts (717d6af), lines 655-726<br><br>export class JobMonitorWorkflow {<br>  /**<br>   * Main workflow execution for job monitoring.<br>   * @param {Env} env - Worker environment bindings.<br>   * @param {object} payload - Configuration for the run.<br>   * @param {string[]} [payload.job_ids] - Optional array of specific job IDs to monitor. If not provided, queries a batch of 50 open jobs.<br>   * @returns {Promise<any>} Summary of the monitoring results.<br>   */<br>  async run(env: Env, payload: { job_ids?: string[] }): Promise<any> {<br>    const { job_ids } = payload;<br>    <br>    try {<br>      // Get jobs to monitor<br>      let jobs: any[];<br>      <br>      if (job_ids && job_ids.length > 0) {<br>        const placeholders = job_ids.map(() => '?').join(',');<br>        const result = await env.DB.prepare(<br>          \`SELECT * FROM jobs WHERE id IN (${placeholders}) AND status = 'open'\`<br>        ).bind(...job_ids).all();<br>        jobs = result.results || [];<br>      } else {<br>        // Monitor all active jobs, prioritizing oldest crawl<br>        const result = await env.DB.prepare(<br>          'SELECT * FROM jobs WHERE status = ? ORDER BY last_crawled_at ASC LIMIT 50'<br>        ).bind('open').all();<br>        jobs = result.results || [];<br>      }<br>      <br>      const results = [];<br>      <br>      for (const job of jobs) {<br>        // Create JobMonitor Durable Object for this job<br>        const monitorId = env.JOB_MONITOR.idFromName(job.id);<br>        const monitor = env.JOB_MONITOR.get(monitorId);<br>        <br>        // First, configure the monitor with job details (also schedules the alarm)<br>        const configResponse = await monitor.fetch('http://localhost/monitor-job', {<br>          method: 'POST',<br>          headers: { 'Content-Type': 'application/json' },<br>          body: JSON.stringify({<br>            job_id: job.id,<br>            url: job.url,<br>          }),<br>        });<br>        <br>        if (!configResponse.ok) {<br>          console.error(\`Failed to configure monitor for job ${job.id}\`);<br>          continue;<br>        }<br>        <br>        // Then check job status immediately (first check)<br>        const checkResponse = await monitor.fetch('http://localhost/check-job', {<br>          method: 'POST',<br>          headers: { 'Content-Type': 'application/json' },<br>        });<br>        <br>        const checkResult = await checkResponse.json();<br>        results.push({<br>          job_id: job.id,<br>          job_title: job.title,<br>          company: job.company,<br>          ...checkResult,<br>        });<br>      }<br>      <br>      return { results, total_monitored: jobs.length };<br>    } catch (error) {<br>      console.error('Job monitor workflow error:', error);<br>      throw error;<br>    }<br>  }<br>` | `typescript<br>src/lib/workflows/job-monitor-workflow.ts, lines 3-63<br><br>export class JobMonitorWorkflow {<br>  async run(env: Env, payload: { job_ids?: string[] }): Promise<any> {<br>    const { job_ids } = payload;<br><br>    try {<br>      let jobs: any[];<br><br>      if (job_ids && job_ids.length > 0) {<br>        const placeholders = job_ids.map(() => '?').join(',');<br>        const result = await env.DB.prepare(<br>          \`SELECT * FROM jobs WHERE id IN (${placeholders}) AND status = 'open'\`<br>        ).bind(...job_ids).all();<br>        jobs = result.results || [];<br>      } else {<br>        const result = await env.DB.prepare(<br>          'SELECT * FROM jobs WHERE status = ? ORDER BY last_crawled_at ASC LIMIT 50'<br>        ).bind('open').all();<br>        jobs = result.results || [];<br>      }<br><br>      const results = [];<br><br>      for (const job of jobs) {<br>        const monitorId = env.JOB_MONITOR.idFromName(job.id);<br>        const monitor = env.JOB_MONITOR.get(monitorId);<br><br>        const configResponse = await monitor.fetch('http://localhost/monitor-job', {<br>          method: 'POST',<br>          headers: { 'Content-Type': 'application/json' },<br>          body: JSON.stringify({<br>            job_id: job.id,<br>            url: job.url,<br>          }),<br>        });<br><br>        if (!configResponse.ok) {<br>          console.error(\`Failed to configure monitor for job ${job.id}\`);<br>          continue;<br>        }<br><br>        const checkResponse = await monitor.fetch('http://localhost/check-job', {<br>          method: 'POST',<br>          headers: { 'Content-Type': 'application/json' },<br>        });<br><br>        const checkResult = await checkResponse.json();<br>        results.push({<br>          job_id: job.id,<br>          job_title: job.title,<br>          company: job.company,<br>          ...checkResult,<br>        });<br>      }<br><br>      return { results, total_monitored: jobs.length };<br>    } catch (error) {<br>      console.error('Job monitor workflow error:', error);<br>      throw error;<br>    }<br>  }<br>}<br>` | ✅ |\n| `typescript<br>src/index.ts (717d6af), lines 736-813<br><br>export class ChangeAnalysisWorkflow {<br>  /**<br>   * Main workflow execution for change analysis.<br>   * @param {Env} env - Worker environment bindings.<br>   * @param {object} payload - Snapshot IDs to compare.<br>   * @param {string} payload.job_id - The ID of the job being analyzed.<br>   * @param {string} payload.from_snapshot_id - The ID of the older snapshot for comparison.<br>   * @param {string} payload.to_snapshot_id - The ID of the newer snapshot for comparison.<br>   * @returns {Promise<any>} The new change record details.<br>   */<br>  async run(env: Env, payload: { job_id: string; from_snapshot_id: string; to_snapshot_id: string }): Promise<any> {<br>    const { job_id, from_snapshot_id, to_snapshot_id } = payload;<br>    <br>    try {<br>      // Get snapshots from database<br>      const fromSnapshot = await env.DB.prepare('SELECT * FROM snapshots WHERE id = ?')<br>        .bind(from_snapshot_id).first();<br>      const toSnapshot = await env.DB.prepare('SELECT * FROM snapshots WHERE id = ?')<br>        .bind(to_snapshot_id).first();<br>      <br>      if (!fromSnapshot || !toSnapshot) {<br>        throw new Error('Snapshots not found');<br>      }<br>      <br>      // Compare snapshots (simplified - could use R2 content comparison)<br>      const diff = {<br>        content_hash_changed: fromSnapshot.content_hash !== toSnapshot.content_hash,<br>        http_status_changed: fromSnapshot.http_status !== toSnapshot.http_status,<br>        etag_changed: fromSnapshot.etag !== toSnapshot.etag,<br>      };<br>      <br>      // Generate semantic summary using AI if content changed<br>      let semanticSummary = 'No significant changes detected';<br>      <br>      if (diff.content_hash_changed) {<br>        // Use AI to analyze changes<br>        const analysisPrompt = \`Analyze the changes between two job posting snapshots and provide a brief summary of what changed.\`;<br>        <br>        const messages = [<br>          {<br>            role: 'system',<br>            content: 'You are an expert at analyzing job posting changes. Provide concise summaries of what changed between job postings.',<br>          },<br>          {<br>            role: 'user',<br>            content: \`${analysisPrompt}\n\nContent hash changed: ${diff.content_hash_changed}\nHTTP status changed: ${diff.http_status_changed}\`,<br>          },<br>        ];<br>        <br>        const aiResponse = await env.AI.run('@cf/meta/llama-3.1-8b-instruct', { messages });<br>        semanticSummary = aiResponse.response || semanticSummary;<br>      }<br>      <br>      // Save change record<br>      const changeId = crypto.randomUUID();<br>      await env.DB.prepare(<br>        'INSERT INTO changes(id, job_id, from_snapshot_id, to_snapshot_id, diff_json, semantic_summary) VALUES(?,?,?,?,?,?)'<br>      ).bind(<br>        changeId,<br>        job_id,<br>        from_snapshot_id,<br>        to_snapshot_id,<br>        JSON.stringify(diff),<br>        semanticSummary<br>      ).run();<br>      <br>      return {<br>        change_id: changeId,<br>        job_id,<br>        diff,<br>        semantic_summary: semanticSummary,<br>      };<br>    } catch (error) {<br>      console.error('Change analysis workflow error:', error);<br>      throw error;<br>    }<br>  }<br>}<br>` | `typescript<br>src/lib/workflows/change-analysis-workflow.ts, lines 3-65<br><br>export class ChangeAnalysisWorkflow {<br>  async run(env: Env, payload: { job_id: string; from_snapshot_id: string; to_snapshot_id: string }): Promise<any> {<br>    const { job_id, from_snapshot_id, to_snapshot_id } = payload;<br><br>    try {<br>      const fromSnapshot = await env.DB.prepare('SELECT * FROM snapshots WHERE id = ?')<br>        .bind(from_snapshot_id).first();<br>      const toSnapshot = await env.DB.prepare('SELECT * FROM snapshots WHERE id = ?')<br>        .bind(to_snapshot_id).first();<br><br>      if (!fromSnapshot || !toSnapshot) {<br>        throw new Error('Snapshots not found');<br>      }<br><br>      const diff = {<br>        content_hash_changed: fromSnapshot.content_hash !== toSnapshot.content_hash,<br>        http_status_changed: fromSnapshot.http_status !== toSnapshot.http_status,<br>        etag_changed: fromSnapshot.etag !== toSnapshot.etag,<br>      };<br><br>      let semanticSummary = 'No significant changes detected';<br><br>      if (diff.content_hash_changed) {<br>        const analysisPrompt = \`Analyze the changes between two job posting snapshots and provide a brief summary of what changed.\`;<br><br>        const messages = [<br>          {<br>            role: 'system',<br>            content: 'You are an expert at analyzing job posting changes. Provide concise summaries of what changed between job postings.',<br>          },<br>          {<br>            role: 'user',<br>            content: \`${analysisPrompt}\n\nContent hash changed: ${diff.content_hash_changed}\nHTTP status changed: ${diff.http_status_changed}\`,<br>          },<br>        ];<br><br>        const aiResponse = await env.AI.run('@cf/meta/llama-3.1-8b-instruct', { messages });<br>        semanticSummary = aiResponse.response || semanticSummary;<br>      }<br><br>      const changeId = crypto.randomUUID();<br>      await env.DB.prepare(<br>        'INSERT INTO changes(id, job_id, from_snapshot_id, to_snapshot_id, diff_json, semantic_summary) VALUES(?,?,?,?,?,?)'<br>      ).bind(<br>        changeId,<br>        job_id,<br>        from_snapshot_id,<br>        to_snapshot_id,<br>        JSON.stringify(diff),<br>        semanticSummary<br>      ).run();<br><br>      return {<br>        change_id: changeId,<br>        job_id,<br>        diff,<br>        semantic_summary: semanticSummary,<br>      };<br>    } catch (error) {<br>      console.error('Change analysis workflow error:', error);<br>      throw error;<br>    }<br>  }<br>` | ✅ |\n| `typescript<br>src/index.ts (717d6af), lines 827-905<br><br>export class ScrapeSocket {<br>  private state: DurableObjectState;<br>  private clients: Map<WebSocket, { type: string; lastPing: number }> = new Map();<br><br>  constructor(state: DurableObjectState) {<br>    this.state = state;<br>  }<br><br>  /**<br>   * Handles all incoming HTTP and WebSocket requests for the ScrapeSocket.<br>   * @param {Request} req - Incoming request object.<br>   * @returns {Promise<Response>} HTTP or WebSocket response.<br>   */<br>  async fetch(req: Request): Promise<Response> {<br>    const url = new URL(req.url);<br><br>    if (url.pathname === '/ws' && req.headers.get('Upgrade') === 'websocket') {<br>      const pair = new WebSocketPair();<br>      const client = pair[0];<br>      const server = pair[1];<br>      server.accept();<br>      const clientType = url.searchParams.get('client') || 'unknown';<br>      this.clients.set(server, { type: clientType, lastPing: Date.now() });<br>      server.addEventListener('close', () => {<br>        this.clients.delete(server);<br>      });<br>      server.addEventListener('message', (evt) => {<br>        if (evt.data === 'ping') {<br>          server.send(JSON.stringify({ type: 'pong' }));<br>          const info = this.clients.get(server);<br>          if (info) {<br>            info.lastPing = Date.now();<br>          }<br>          return;<br>        }<br>        // Broadcast any other messages to all connected clients<br>        for (const ws of this.clients.keys()) {<br>          if (ws !== server) {<br>            try {<br>              ws.send(evt.data);<br>            } catch {<br>              this.clients.delete(ws);<br>            }<br>          }<br>        }<br>      });<br>      return new Response(null, { status: 101, webSocket: client });<br>    }<br><br>    if (url.pathname === '/dispatch' && req.method === 'POST') {<br>      const message = await req.text();<br>      for (const ws of this.clients.keys()) {<br>        try {<br>          ws.send(message);<br>        } catch {<br>          this.clients.delete(ws);<br>        }<br>      }<br>      return new Response('sent', { status: 200 });<br>    }<br><br>    if (url.pathname === '/status' && req.method === 'GET') {<br>      const now = Date.now();<br>      const CLIENT_TIMEOUT_MS = 60_000;<br>      const pythonConnected = Array.from(this.clients.entries()).some(([, info]) =><br>        info.type === 'python' && now - info.lastPing < CLIENT_TIMEOUT_MS,<br>      );<br>      return new Response(<br>        JSON.stringify({<br>          pythonConnected,<br>          connections: this.clients.size,<br>        }),<br>        { headers: { 'Content-Type': 'application/json' } },<br>      );<br>    }<br><br>    return new Response('Not Found', { status: 404 });<br>  }<br>}<br>` | `typescript<br>src/lib/durable-objects/scrape-socket.ts, lines 3-69<br><br>export class ScrapeSocket {<br>  private state: DurableObjectState;<br>  private clients: Map<WebSocket, { type: string; lastPing: number }> = new Map();<br><br>  constructor(state: DurableObjectState) {<br>    this.state = state;<br>  }<br><br>  async fetch(req: Request): Promise<Response> {<br>    const url = new URL(req.url);<br><br>    if (url.pathname === '/ws' && req.headers.get('Upgrade') === 'websocket') {<br>      const pair = new WebSocketPair();<br>      const client = pair[0];<br>      const server = pair[1];<br>      server.accept();<br>      const clientType = url.searchParams.get('client') || 'unknown';<br>      this.clients.set(server, { type: clientType, lastPing: Date.now() });<br>      server.addEventListener('close', () => {<br>        this.clients.delete(server);<br>      });<br>      server.addEventListener('message', (evt) => {<br>        if (evt.data === 'ping') {<br>          server.send(JSON.stringify({ type: 'pong' }));<br>          const info = this.clients.get(server);<br>          if (info) {<br>            info.lastPing = Date.now();<br>          }<br>          return;<br>        }<br>        const info = this.clients.get(server);<br>        console.log(\`Received message from client with type '${info?.type}':\`, evt.data);<br>        // TODO: Process incoming messages from clients here instead of broadcasting.<br>      });<br>      return new Response(null, { status: 101, webSocket: client });<br>    }<br><br>    if (url.pathname === '/dispatch' && req.method === 'POST') {<br>      const message = await req.text();<br>      for (const ws of this.clients.keys()) {<br>        try {<br>          ws.send(message);<br>        } catch {<br>          this.clients.delete(ws);<br>        }<br>      }<br>      return new Response('sent', { status: 200 });<br>    }<br><br>    if (url.pathname === '/status' && req.method === 'GET') {<br>      const now = Date.now();<br>      const CLIENT_TIMEOUT_MS = 60_000;<br>      const pythonConnected = Array.from(this.clients.entries()).some(([, info]) =><br>        info.type === 'python' && now - info.lastPing < CLIENT_TIMEOUT_MS,<br>      );<br>      return new Response(<br>        JSON.stringify({<br>          pythonConnected,<br>          connections: this.clients.size,<br>        }),<br>        { headers: { 'Content-Type': 'application/json' } },<br>      );<br>    }<br><br>    return new Response('Not Found', { status: 404 });<br>  }<br>}<br>` | ✅ (message broadcasting removed in favor of logging and TODO for server-side processing to mitigate data leakage) |\n| `typescript<br>src/index.ts (717d6af), lines 919-985<br><br>  async fetch(request: Request, env: Env): Promise<Response> {<br>    const url = new URL(request.url);<br><br>    // Serve static files from ASSETS binding<br>    if (url.pathname === '/' || url.pathname === '/index.html') {<br>      const response = await env.ASSETS.fetch(new Request(new URL('/index.html', url.origin)));<br>      return response;<br>    }<br><br>    if (url.pathname === '/openapi.json') {<br>      const response = await env.ASSETS.fetch(request);<br>      if (response.ok) {<br>        return new Response(response.body, {<br>          headers: {<br>            ...response.headers,<br>            'Content-Type': 'application/json',<br>          },<br>        });<br>      }<br>    }<br><br>    // WebSocket troubleshooting page<br>    if (url.pathname === '/ws-debug' || url.pathname === '/ws-debug.html') {<br>      const response = await env.ASSETS.fetch(new Request(new URL('/ws-debug.html', url.origin)));<br>      return response;<br>    }<br><br>    // Health check endpoint (unauthenticated)<br>    if (url.pathname === '/api/health') {<br>      return new Response(JSON.stringify({<br>        status: 'healthy',<br>        timestamp: new Date().toISOString(),<br>        version: '1.0.0'<br>      }), { <br>        status: 200,<br>        headers: { 'Content-Type': 'application/json' }<br>      });<br>    }<br><br>    // Email routing for Cloudflare Email Routing (no auth required, handles multipart/form-data)<br>    if (request.method === 'POST' && request.headers.get('content-type')?.includes('multipart/form-data')) {<br>      // This is likely an incoming email from Cloudflare Email Routing<br>      return handleEmailReceived(request, env);<br>    }<br><br>    // WebSocket upgrade request (no auth required)<br>    if (url.pathname === '/ws' && request.headers.get('Upgrade') === 'websocket') {<br>      // Delegates to the ScrapeSocket Durable Object<br>      return handleScrapeSocket(request, env);<br>    }<br><br>    // Serve all other non-API paths as static assets<br>    if (!url.pathname.startsWith('/api/')) {<br>      try {<br>        const response = await env.ASSETS.fetch(request);<br>        if (response.ok) {<br>          return response;<br>        }<br>      } catch (error) {<br>        console.error("Error fetching from ASSETS:", error);<br>      }<br><br>      return new Response('Not Found', {<br>        status: 404,<br>        headers: { 'Content-Type': 'text/html' },<br>      });<br>    }<br><br>` | `typescript<br>src/index.ts, lines 25-41 & src/routes/pages.ts, lines 1-78<br><br>export default {<br>  async fetch(request: Request, env: Env): Promise<Response> {<br>    const url = new URL(request.url);<br><br>    if (isEmailIngestRequest(request)) {<br>      return handleEmailIngest(request, env);<br>    }<br><br>    if (url.pathname === '/ws' && request.headers.get('Upgrade') === 'websocket') {<br>      return handleScrapeSocket(request, env);<br>    }<br><br>    if (!url.pathname.startsWith('/api/')) {<br>      return handlePageRequest(request, env);<br>    }<br><br>    return handleApiRequest(request, env);<br>  },<br><br>import type { Env } from '../lib/env';<br><br>function normalisePath(pathname: string): string {<br>  if (!pathname) {<br>    return '/';<br>  }<br>  let path = pathname;<br>  if (!path.startsWith('/')) {<br>    path = \`/${path}\`;<br>  }<br>  if (path.length > 1 && path.endsWith('/')) {<br>    path = path.slice(0, -1);<br>  }<br>  return path || '/';<br>}<br><br>const PAGE_ROUTES: Record<string, { assetPath: string; contentType?: string }> = {<br>  '/': { assetPath: '/index.html', contentType: 'text/html; charset=UTF-8' },<br>  '/index.html': { assetPath: '/index.html', contentType: 'text/html; charset=UTF-8' },<br>  '/getting-started': { assetPath: '/getting-started.html', contentType: 'text/html; charset=UTF-8' },<br>  '/getting-started.html': { assetPath: '/getting-started.html', contentType: 'text/html; charset=UTF-8' },<br>  '/api-reference': { assetPath: '/api-reference.html', contentType: 'text/html; charset=UTF-8' },<br>  '/api-reference.html': { assetPath: '/api-reference.html', contentType: 'text/html; charset=UTF-8' },<br>  '/email-integration': { assetPath: '/email-integration.html', contentType: 'text/html; charset=UTF-8' },<br>  '/email-integration.html': { assetPath: '/email-integration.html', contentType: 'text/html; charset=UTF-8' },<br>  '/job-history-management': { assetPath: '/job-history-management.html', contentType: 'text/html; charset=UTF-8' },<br>  '/job-history-management.html': { assetPath: '/job-history-management.html', contentType: 'text/html; charset=UTF-8' },<br>  '/agent-workflow-config': { assetPath: '/agent-workflow-config.html', contentType: 'text/html; charset=UTF-8' },<br>  '/agent-workflow-config.html': { assetPath: '/agent-workflow-config.html', contentType: 'text/html; charset=UTF-8' },<br>  '/operations-dashboard': { assetPath: '/operations-dashboard.html', contentType: 'text/html; charset=UTF-8' },<br>  '/operations-dashboard.html': { assetPath: '/operations-dashboard.html', contentType: 'text/html; charset=UTF-8' },<br>  '/logs': { assetPath: '/logs.html', contentType: 'text/html; charset=UTF-8' },<br>  '/logs.html': { assetPath: '/logs.html', contentType: 'text/html; charset=UTF-8' },<br>  '/ws-debug': { assetPath: '/ws-debug.html', contentType: 'text/html; charset=UTF-8' },<br>  '/ws-debug.html': { assetPath: '/ws-debug.html', contentType: 'text/html; charset=UTF-8' },<br>  '/templates/cover_letter_template': { assetPath: '/templates/cover_letter_template.html', contentType: 'text/html; charset=UTF-8' },<br>  '/templates/cover_letter_template.html': { assetPath: '/templates/cover_letter_template.html', contentType: 'text/html; charset=UTF-8' },<br>  '/templates/resume_template': { assetPath: '/templates/resume_template.html', contentType: 'text/html; charset=UTF-8' },<br>  '/templates/resume_template.html': { assetPath: '/templates/resume_template.html', contentType: 'text/html; charset=UTF-8' },<br>  '/templates/email_template': { assetPath: '/templates/email_template.html', contentType: 'text/html; charset=UTF-8' },<br>  '/templates/email_template.html': { assetPath: '/templates/email_template.html', contentType: 'text/html; charset=UTF-8' },<br>  '/openapi.json': { assetPath: '/openapi.json', contentType: 'application/json; charset=UTF-8' },<br>};<br><br>export async function handlePageRequest(request: Request, env: Env): Promise<Response> {<br>  const url = new URL(request.url);<br>  const pathname = normalisePath(url.pathname);<br><br>  if (request.method !== 'GET' && request.method !== 'HEAD') {<br>    return new Response('Method Not Allowed', { status: 405 });<br>  }<br><br>  const route = PAGE_ROUTES[pathname];<br>  if (route) {<br>    const assetUrl = new URL(route.assetPath, url.origin);<br>    const assetRequest = new Request(assetUrl.toString(), {<br>      method: request.method,<br>      headers: new Headers(request.headers),<br>    });<br>    const assetResponse = await env.ASSETS.fetch(assetRequest);<br><br>    if (assetResponse.ok) {<br>      if (route.contentType) {<br>        const headers = new Headers(assetResponse.headers);<br>        headers.set('Content-Type', route.contentType);<br>        return new Response(assetResponse.body, {<br>          status: assetResponse.status,<br>          headers,<br>        });<br>      }<br>      return assetResponse;<br>    }<br>  }<br><br>  const assetResponse = await env.ASSETS.fetch(request);<br>  if (assetResponse.status !== 404) {<br>    return assetResponse;<br>  }<br><br>  return new Response('Not Found', {<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 958-962<br><br>    // Email routing for Cloudflare Email Routing (no auth required, handles multipart/form-data)<br>    if (request.method === 'POST' && request.headers.get('content-type')?.includes('multipart/form-data')) {<br>      // This is likely an incoming email from Cloudflare Email Routing<br>      return handleEmailReceived(request, env);<br>    }<br><br>` | `typescript<br>src/index.ts, lines 29-31 & src/routes/email-ingest.ts, lines 4-10<br><br>    if (isEmailIngestRequest(request)) {<br>      return handleEmailIngest(request, env);<br>    }<br><br>export function isEmailIngestRequest(request: Request): boolean {<br>  const contentType = request.headers.get('content-type') || '';<br>  return request.method === 'POST' && contentType.includes('multipart/form-data');<br>}<br><br>export function handleEmailIngest(request: Request, env: Env): Promise<Response> {<br>  return handleEmailReceived(request, env);<br>}<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 964-968<br><br>    // WebSocket upgrade request (no auth required)<br>    if (url.pathname === '/ws' && request.headers.get('Upgrade') === 'websocket') {<br>      // Delegates to the ScrapeSocket Durable Object<br>      return handleScrapeSocket(request, env);<br>    }<br><br>` | `typescript<br>src/index.ts, lines 33-35 & src/routes/socket.ts, lines 1-28<br><br>    if (url.pathname === '/ws' && request.headers.get('Upgrade') === 'websocket') {<br>      return handleScrapeSocket(request, env);<br>    }<br><br>import type { Env } from '../lib/env';<br><br>export async function handleScrapeSocket(request: Request, env: Env): Promise<Response> {<br>  const url = new URL(request.url);<br><br>  // Support auth via header or \`?token=\` query param for browser-based debugging<br>  let auth = request.headers.get('Authorization') || '';<br>  if (!auth) {<br>    const token = url.searchParams.get('token');<br>    if (token) {<br>      auth = \`Bearer ${token}\`;<br>    }<br>  }<br>  const expected = \`Bearer ${env.API_AUTH_TOKEN}\`;<br><br>  let diff = auth.length ^ expected.length;<br>  for (let i = 0; i < auth.length && i < expected.length; i++) {<br>    diff |= auth.charCodeAt(i) ^ expected.charCodeAt(i);<br>  }<br><br>  if (diff !== 0) {<br>    return new Response('Unauthorized', { status: 401 });<br>  }<br><br>  const id = env.SCRAPE_SOCKET.idFromName('default');<br>  const stub = env.SCRAPE_SOCKET.get(id);<br>  return stub.fetch(request);<br>}<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 987-1024<br><br>    // Handle OPTIONS requests for CORS (Scraper and Logs endpoints)<br>    const isScraperEndpoint = url.pathname.startsWith('/api/scraper/');<br>    if (request.method === 'OPTIONS' && isScraperEndpoint) {<br>      return handleScraperOptions();<br>    }<br><br>    const isLogsEndpoint = url.pathname.startsWith('/api/logs');<br>    if (request.method === 'OPTIONS' && isLogsEndpoint) {<br>      return handleLogsOptions();<br>    }<br><br>    // Define unauthenticated API routes (primarily for scrapers/loggers)<br>    const unauthenticatedApiRoutes = [<br>      { method: 'POST', path: '/api/scraper/job-details' },<br>      { method: 'GET', path: '/api/scraper/queue/pending' },<br>      { method: 'GET', path: '/api/scraper/queue/unrecorded' },<br>      { method: 'GET', path: '/api/scraper/monitored-jobs' },<br>      { method: 'POST', path: '/api/logs' },<br>      { method: 'GET', path: '/api/logs' },<br>      { method: 'GET', path: '/api/logs/meta' }<br>    ];<br><br>    // Authorization check<br>    const requiresAuth = url.pathname.startsWith('/api/') &&<br>      url.pathname !== '/api/health' &&<br>      !unauthenticatedApiRoutes.some((route) => route.method === request.method && route.path === url.pathname);<br><br>    if (requiresAuth) {<br>      const authHeader = request.headers.get('Authorization');<br>      const expectedToken = \`Bearer ${env.API_AUTH_TOKEN}\`;<br><br>      if (!authHeader || authHeader !== expectedToken) {<br>        return new Response(JSON.stringify({ error: 'Unauthorized' }), {<br>          status: 401,<br>          headers: { 'Content-Type': 'application/json' },<br>        });<br>      }<br>    }<br><br>` | `typescript<br>src/routes/api.ts, lines 69-112<br><br>  const url = new URL(request.url);<br><br>  if (url.pathname === '/api/health') {<br>    return new Response(JSON.stringify({<br>      status: 'healthy',<br>      timestamp: new Date().toISOString(),<br>      version: '1.0.0',<br>    }), {<br>      status: 200,<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br><br>  const isScraperEndpoint = url.pathname.startsWith('/api/scraper/');<br>  if (request.method === 'OPTIONS' && isScraperEndpoint) {<br>    return handleScraperOptions();<br>  }<br><br>  const isLogsEndpoint = url.pathname.startsWith('/api/logs');<br>  if (request.method === 'OPTIONS' && isLogsEndpoint) {<br>    return handleLogsOptions();<br>  }<br><br>  const unauthenticatedApiRoutes = [<br>    { method: 'POST', path: '/api/scraper/job-details' },<br>    { method: 'GET', path: '/api/scraper/queue/pending' },<br>    { method: 'GET', path: '/api/scraper/queue/unrecorded' },<br>    { method: 'GET', path: '/api/scraper/monitored-jobs' },<br>    { method: 'POST', path: '/api/logs' },<br>    { method: 'GET', path: '/api/logs' },<br>    { method: 'GET', path: '/api/logs/meta' },<br>  ];<br><br>  const requiresAuth = url.pathname.startsWith('/api/') &&<br>    url.pathname !== '/api/health' &&<br>    !unauthenticatedApiRoutes.some((route) => route.method === request.method && route.path === url.pathname);<br><br>  if (requiresAuth) {<br>    const authHeader = request.headers.get('Authorization');<br>    const expectedToken = \`Bearer ${env.API_AUTH_TOKEN}\`;<br><br>    if (!authHeader || authHeader !== expectedToken) {<br>      return new Response(JSON.stringify({ error: 'Unauthorized' }), {<br>        status: 401,<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 1026-1031<br><br>    // Dedicated status endpoint for ScrapeSocket DO<br>    if (url.pathname === '/api/socket/status' && request.method === 'GET') {<br>      const id = env.SCRAPE_SOCKET.idFromName('default');<br>      const stub = env.SCRAPE_SOCKET.get(id);<br>      return stub.fetch('https://dummy/status');<br>    }<br><br>` | `typescript<br>src/routes/api.ts, lines 113-120<br><br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    }<br>  }<br><br>  if (url.pathname === '/api/socket/status' && request.method === 'GET') {<br>    const id = env.SCRAPE_SOCKET.idFromName('default');<br>    const stub = env.SCRAPE_SOCKET.get(id);<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 1033-1063<br><br>    try {<br>      // --- Route Mapping (grouped by functionality) ---<br><br>      // Scraper / Logs Endpoints<br>      if (url.pathname === '/api/scrape/dispatch' && request.method === 'POST') {<br>        return handleScrapeDispatch(request, env);<br>      }<br>      if (url.pathname === '/api/logs' && request.method === 'POST') {<br>        return handleLogsPost(request, env);<br>      }<br>      if (url.pathname === '/api/logs' && request.method === 'GET') {<br>        return handleLogsGet(request, env);<br>      }<br>      if (url.pathname === '/api/logs/meta' && request.method === 'GET') {<br>        return handleLogsMetaGet(request, env);<br>      }<br>      if (url.pathname === '/api/scraper/queue' && request.method === 'POST') {<br>        return handleScrapeQueuePost(request, env);<br>      }<br>      if (url.pathname === '/api/scraper/queue/pending' && request.method === 'GET') {<br>        return handleScrapeQueuePendingGet(request, env);<br>      }<br>      if (url.pathname === '/api/scraper/queue/unrecorded' && request.method === 'GET') {<br>        return handleScrapeQueueUnrecordedGet(request, env);<br>      }<br>      if (url.pathname === '/api/scraper/job-details' && request.method === 'POST') {<br>        return handleScrapedJobDetailsPost(request, env);<br>      }<br>      if (url.pathname === '/api/scraper/monitored-jobs' && request.method === 'GET') {<br>        return handleScraperMonitoredJobsGet(request, env);<br>      }<br><br>` | `typescript<br>src/routes/api.ts, lines 121-158<br><br>    return stub.fetch('https://dummy/status');<br>  }<br><br>  // Scraper & Logs endpoints<br>  if (url.pathname === '/api/scrape/dispatch' && request.method === 'POST') {<br>    return handleScrapeDispatch(request, env);<br>  }<br>  if (url.pathname === '/api/logs' && request.method === 'POST') {<br>    return handleLogsPost(request, env);<br>  }<br>  if (url.pathname === '/api/logs' && request.method === 'GET') {<br>    return handleLogsGet(request, env);<br>  }<br>  if (url.pathname === '/api/logs/meta' && request.method === 'GET') {<br>    return handleLogsMetaGet(request, env);<br>  }<br>  if (url.pathname === '/api/scraper/queue' && request.method === 'POST') {<br>    return handleScrapeQueuePost(request, env);<br>  }<br>  if (url.pathname === '/api/scraper/queue/pending' && request.method === 'GET') {<br>    return handleScrapeQueuePendingGet(request, env);<br>  }<br>  if (url.pathname === '/api/scraper/queue/unrecorded' && request.method === 'GET') {<br>    return handleScrapeQueueUnrecordedGet(request, env);<br>  }<br>  if (url.pathname === '/api/scraper/job-details' && request.method === 'POST') {<br>    return handleScrapedJobDetailsPost(request, env);<br>  }<br>  if (url.pathname === '/api/scraper/monitored-jobs' && request.method === 'GET') {<br>    return handleScraperMonitoredJobsGet(request, env);<br>  }<br><br>  // Job scraping & monitoring<br>  if (url.pathname === '/api/jobs' && request.method === 'GET') {<br>    return handleJobsGet(request, env);<br>  }<br>  if (url.pathname === '/api/jobs/monitoring-queue' && request.method === 'GET') {<br>    return handleMonitoringQueueGet(request, env);<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 1065-1098<br><br>      // Job Scraping & Monitoring API Routes<br>      if (url.pathname === '/api/jobs' && request.method === 'GET') {<br>        return handleJobsGet(request, env);<br>      }<br>      if (url.pathname.startsWith('/api/jobs/') && request.method === 'GET') {<br>        // Tracking, Snapshot Content, and Job Detail Routes<br>        if (url.pathname.endsWith('/tracking')) {<br>          return handleJobTrackingGet(request, env);<br>        }<br>        if (url.pathname.includes('/snapshots/') && url.pathname.endsWith('/content')) {<br>          return handleSnapshotContentGet(request, env);<br>        }<br>        // Default job detail route<br>        const params = parsePathParams(url.pathname, '/api/jobs/:id');<br>        if (!params || !params.id) {<br>          return new Response(JSON.stringify({ error: 'Job ID is required' }), {<br>            status: 400,<br>            headers: { 'Content-Type': 'application/json' },<br>          });<br>        }<br>        return handleJobGet(request, env, params.id);<br>      }<br>      if (url.pathname.startsWith('/api/jobs/') && url.pathname.endsWith('/monitoring') && request.method === 'PUT') {<br>        return handleJobMonitoringPut(request, env);<br>      }<br>      if (url.pathname === '/api/monitoring/daily-run' && request.method === 'POST') {<br>        return handleDailyMonitoringPost(request, env);<br>      }<br>      if (url.pathname === '/api/monitoring/status' && request.method === 'GET') {<br>        return handleMonitoringStatusGet(request, env);<br>      }<br>      if (url.pathname === '/api/jobs/monitoring-queue' && request.method === 'GET') {<br>        return handleMonitoringQueueGet(request, env);<br>      }<br><br>` | `typescript<br>src/routes/api.ts, lines 159-205<br><br>  }<br>  if (url.pathname.startsWith('/api/jobs/') && request.method === 'GET') {<br>    if (url.pathname.endsWith('/tracking')) {<br>      return handleJobTrackingGet(request, env);<br>    }<br>    if (url.pathname.includes('/snapshots/') && url.pathname.endsWith('/content')) {<br>      return handleSnapshotContentGet(request, env);<br>    }<br>    const params = parsePathParams(url.pathname, '/api/jobs/:id');<br>    if (!params || !params.id) {<br>      return new Response(JSON.stringify({ error: 'Job ID is required' }), {<br>        status: 400,<br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    }<br>    return handleJobGet(request, env, params.id);<br>  }<br>  if (url.pathname.startsWith('/api/jobs/') && url.pathname.endsWith('/monitoring') && request.method === 'PUT') {<br>    return handleJobMonitoringPut(request, env);<br>  }<br>  if (url.pathname === '/api/monitoring/daily-run' && request.method === 'POST') {<br>    return handleDailyMonitoringPost(request, env);<br>  }<br>  if (url.pathname === '/api/monitoring/status' && request.method === 'GET') {<br>    return handleMonitoringStatusGet(request, env);<br>  }<br>  // Run & config endpoints<br>  if (url.pathname === '/api/runs' && request.method === 'GET') {<br>    return handleRunsGet(request, env);<br>  }<br>  if (url.pathname === '/api/runs/discovery' && request.method === 'POST') {<br>    return handleDiscoveryRunPost(request, env);<br>  }<br>  if (url.pathname === '/api/runs/monitor' && request.method === 'POST') {<br>    return handleMonitorRunPost(request, env);<br>  }<br>  if (url.pathname === '/api/configs' && request.method === 'GET') {<br>    return handleConfigsGet(request, env);<br>  }<br>  if (url.pathname === '/api/configs' && request.method === 'POST') {<br>    return handleConfigsPost(request, env);<br>  }<br><br>  // Agent management<br>  if (url.pathname === '/api/agent/query' && request.method === 'GET') {<br>    return handleAgentQuery(request, env);<br>  }<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 1100-1115<br><br>      // Run & Config Endpoints (Orchestration/Control)<br>      if (url.pathname === '/api/runs' && request.method === 'GET') {<br>        return handleRunsGet(request, env);<br>      }<br>      if (url.pathname === '/api/runs/discovery' && request.method === 'POST') {<br>        return handleDiscoveryRunPost(request, env);<br>      }<br>      if (url.pathname === '/api/runs/monitor' && request.method === 'POST') {<br>        return handleMonitorRunPost(request, env);<br>      }<br>      if (url.pathname === '/api/configs' && request.method === 'GET') {<br>        return handleConfigsGet(request, env);<br>      }<br>      if (url.pathname === '/api/configs' && request.method === 'POST') {<br>        return handleConfigsPost(request, env);<br>      }<br><br>` | `typescript<br>src/routes/api.ts, lines 206-225<br><br>  if (url.pathname === '/api/agents' && request.method === 'GET') {<br>    return handleAgentsGet(request, env);<br>  }<br>  if (url.pathname === '/api/agents' && request.method === 'POST') {<br>    return handleAgentsPost(request, env);<br>  }<br>  if (url.pathname.startsWith('/api/agents/') && request.method === 'GET') {<br>    const params = parsePathParams(url.pathname, '/api/agents/:id');<br>    if (!params || !params.id) {<br>      return new Response(JSON.stringify({ error: 'Agent ID is required' }), {<br>        status: 400,<br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    }<br>    return handleAgentGet(request, env, params.id);<br>  }<br>  if (url.pathname.startsWith('/api/agents/') && request.method === 'PUT') {<br>    const params = parsePathParams(url.pathname, '/api/agents/:id');<br>    if (!params || !params.id) {<br>      return new Response(JSON.stringify({ error: 'Agent ID is required' }), {<br>        status: 400,<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 1117-1157<br><br>      // Agent Management Endpoints<br>      if (url.pathname === '/api/agent/query' && request.method === 'GET') {<br>        return handleAgentQuery(request, env);<br>      }<br>      if (url.pathname === '/api/agents' && request.method === 'GET') {<br>        return handleAgentsGet(request, env);<br>      }<br>      if (url.pathname === '/api/agents' && request.method === 'POST') {<br>        return handleAgentsPost(request, env);<br>      }<br>      if (url.pathname.startsWith('/api/agents/') && request.method === 'GET') {<br>        const params = parsePathParams(url.pathname, '/api/agents/:id');<br>        if (!params || !params.id) {<br>          return new Response(JSON.stringify({ error: 'Agent ID is required' }), {<br>            status: 400,<br>            headers: { 'Content-Type': 'application/json' },<br>          });<br>        }<br>        return handleAgentGet(request, env, params.id);<br>      }<br>      if (url.pathname.startsWith('/api/agents/') && request.method === 'PUT') {<br>        const params = parsePathParams(url.pathname, '/api/agents/:id');<br>        if (!params || !params.id) {<br>          return new Response(JSON.stringify({ error: 'Agent ID is required' }), {<br>            status: 400,<br>            headers: { 'Content-Type': 'application/json' },<br>          });<br>        }<br>        return handleAgentPut(request, env, params.id);<br>      }<br>      if (url.pathname.startsWith('/api/agents/') && request.method === 'DELETE') {<br>        const params = parsePathParams(url.pathname, '/api/agents/:id');<br>        if (!params || !params.id) {<br>          return new Response(JSON.stringify({ error: 'Agent ID is required' }), {<br>            status: 400,<br>            headers: { 'Content-Type': 'application/json' },<br>          });<br>        }<br>        return handleAgentDelete(request, env, params.id);<br>      }<br><br>      // Task Management Endpoints<br>` | `typescript<br>src/routes/api.ts, lines 227-246<br><br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    }<br>    return handleAgentPut(request, env, params.id);<br>  }<br>  if (url.pathname.startsWith('/api/agents/') && request.method === 'DELETE') {<br>    const params = parsePathParams(url.pathname, '/api/agents/:id');<br>    if (!params || !params.id) {<br>      return new Response(JSON.stringify({ error: 'Agent ID is required' }), {<br>        status: 400,<br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    }<br>    return handleAgentDelete(request, env, params.id);<br>  }<br><br>  // Task management<br>  if (url.pathname === '/api/tasks' && request.method === 'GET') {<br>    return handleTasksGet(request, env);<br>  }<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 1159-1194<br><br>      if (url.pathname === '/api/tasks' && request.method === 'GET') {<br>        return handleTasksGet(request, env);<br>      }<br>      if (url.pathname === '/api/tasks' && request.method === 'POST') {<br>        return handleTasksPost(request, env);<br>      }<br>      if (url.pathname.startsWith('/api/tasks/') && request.method === 'GET') {<br>        const params = parsePathParams(url.pathname, '/api/tasks/:id');<br>        if (!params || !params.id) {<br>          return new Response(JSON.stringify({ error: 'Task ID is required' }), {<br>            status: 400,<br>            headers: { 'Content-Type': 'application/json' },<br>          });<br>        }<br>        return handleTaskGet(request, env, params.id);<br>      }<br>      if (url.pathname.startsWith('/api/tasks/') && request.method === 'PUT') {<br>        const params = parsePathParams(url.pathname, '/api/tasks/:id');<br>        if (!params || !params.id) {<br>          return new Response(JSON.stringify({ error: 'Task ID is required' }), {<br>            status: 400,<br>            headers: { 'Content-Type': 'application/json' },<br>          });<br>        }<br>        return handleTaskPut(request, env, params.id);<br>      }<br>      if (url.pathname.startsWith('/api/tasks/') && request.method === 'DELETE') {<br>        const params = parsePathParams(url.pathname, '/api/tasks/:id');<br>        if (!params || !params.id) {<br>          return new Response(JSON.stringify({ error: 'Task ID is required' }), {<br>            status: 400,<br>            headers: { 'Content-Type': 'application/json' },<br>          });<br>        }<br>        return handleTaskDelete(request, env, params.id);<br>      }<br><br>` | `typescript<br>src/routes/api.ts, lines 247-291<br><br>  if (url.pathname === '/api/tasks' && request.method === 'POST') {<br>    return handleTasksPost(request, env);<br>  }<br>  if (url.pathname.startsWith('/api/tasks/') && request.method === 'GET') {<br>    const params = parsePathParams(url.pathname, '/api/tasks/:id');<br>    if (!params || !params.id) {<br>      return new Response(JSON.stringify({ error: 'Task ID is required' }), {<br>        status: 400,<br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    }<br>    return handleTaskGet(request, env, params.id);<br>  }<br>  if (url.pathname.startsWith('/api/tasks/') && request.method === 'PUT') {<br>    const params = parsePathParams(url.pathname, '/api/tasks/:id');<br>    if (!params || !params.id) {<br>      return new Response(JSON.stringify({ error: 'Task ID is required' }), {<br>        status: 400,<br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    }<br>    return handleTaskPut(request, env, params.id);<br>  }<br>  if (url.pathname.startsWith('/api/tasks/') && request.method === 'DELETE') {<br>    const params = parsePathParams(url.pathname, '/api/tasks/:id');<br>    if (!params || !params.id) {<br>      return new Response(JSON.stringify({ error: 'Task ID is required' }), {<br>        status: 400,<br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    }<br>    return handleTaskDelete(request, env, params.id);<br>  }<br><br>  // Workflow management<br>  if (url.pathname === '/api/workflows' && request.method === 'GET') {<br>    return handleWorkflowsGet(request, env);<br>  }<br>  if (url.pathname === '/api/workflows' && request.method === 'POST') {<br>    return handleWorkflowsPost(request, env);<br>  }<br>  if (url.pathname.startsWith('/api/workflows/') && url.pathname.endsWith('/execute') && request.method === 'POST') {<br>    const params = parsePathParams(url.pathname, '/api/workflows/:id/execute');<br>    if (!params || !params.id) {<br>      return new Response(JSON.stringify({ error: 'Workflow ID is required' }), {<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 1196-1242<br><br>      // Workflow Management Endpoints<br>      if (url.pathname === '/api/workflows' && request.method === 'GET') {<br>        return handleWorkflowsGet(request, env);<br>      }<br>      if (url.pathname === '/api/workflows' && request.method === 'POST') {<br>        return handleWorkflowsPost(request, env);<br>      }<br>      if (url.pathname.startsWith('/api/workflows/') && url.pathname.endsWith('/execute') && request.method === 'POST') {<br>        const params = parsePathParams(url.pathname, '/api/workflows/:id/execute');<br>        if (!params || !params.id) {<br>          return new Response(JSON.stringify({ error: 'Workflow ID is required' }), {<br>            status: 400,<br>            headers: { 'Content-Type': 'application/json' },<br>          });<br>        }<br>        return handleWorkflowExecute(request, env, params.id);<br>      }<br>      if (url.pathname.startsWith('/api/workflows/') && request.method === 'GET') {<br>        const params = parsePathParams(url.pathname, '/api/workflows/:id');<br>        if (!params || !params.id) {<br>          return new Response(JSON.stringify({ error: 'Workflow ID is required' }), {<br>            status: 400,<br>            headers: { 'Content-Type': 'application/json' },<br>          });<br>        }<br>        return handleWorkflowGet(request, env, params.id);<br>      }<br>      if (url.pathname.startsWith('/api/workflows/') && request.method === 'PUT') {<br>        const params = parsePathParams(url.pathname, '/api/workflows/:id');<br>        if (!params || !params.id) {<br>          return new Response(JSON.stringify({ error: 'Workflow ID is required' }), {<br>            status: 400,<br>            headers: { 'Content-Type': 'application/json' },<br>          });<br>        }<br>        return handleWorkflowPut(request, env, params.id);<br>      }<br>      if (url.pathname.startsWith('/api/workflows/') && request.method === 'DELETE') {<br>        const params = parsePathParams(url.pathname, '/api/workflows/:id');<br>        if (!params || !params.id) {<br>          return new Response(JSON.stringify({ error: 'Workflow ID is required' }), {<br>            status: 400,<br>            headers: { 'Content-Type': 'application/json' },<br>          });<br>        }<br>        return handleWorkflowDelete(request, env, params.id);<br>      }<br><br>` | `typescript<br>src/routes/api.ts, lines 292-334<br><br>        status: 400,<br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    }<br>    return handleWorkflowExecute(request, env, params.id);<br>  }<br>  if (url.pathname.startsWith('/api/workflows/') && request.method === 'GET') {<br>    const params = parsePathParams(url.pathname, '/api/workflows/:id');<br>    if (!params || !params.id) {<br>      return new Response(JSON.stringify({ error: 'Workflow ID is required' }), {<br>        status: 400,<br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    }<br>    return handleWorkflowGet(request, env, params.id);<br>  }<br>  if (url.pathname.startsWith('/api/workflows/') && request.method === 'PUT') {<br>    const params = parsePathParams(url.pathname, '/api/workflows/:id');<br>    if (!params || !params.id) {<br>      return new Response(JSON.stringify({ error: 'Workflow ID is required' }), {<br>        status: 400,<br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    }<br>    return handleWorkflowPut(request, env, params.id);<br>  }<br>  if (url.pathname.startsWith('/api/workflows/') && request.method === 'DELETE') {<br>    const params = parsePathParams(url.pathname, '/api/workflows/:id');<br>    if (!params || !params.id) {<br>      return new Response(JSON.stringify({ error: 'Workflow ID is required' }), {<br>        status: 400,<br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    }<br>    return handleWorkflowDelete(request, env, params.id);<br>  }<br><br>  // Job history & ratings<br>  if (url.pathname === '/api/applicant/history' && request.method === 'POST') {<br>    return handleJobHistoryPost(request, env);<br>  }<br>  if (url.pathname.startsWith('/api/applicant/') && url.pathname.endsWith('/history') && request.method === 'GET') {<br>    const params = parsePathParams(url.pathname, '/api/applicant/:user_id/history');<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 1244-1270<br><br>      // Job History & Rating Endpoints<br>      if (url.pathname === '/api/applicant/history' && request.method === 'POST') {<br>        return handleJobHistoryPost(request, env);<br>      }<br>      if (url.pathname.startsWith('/api/applicant/') && url.pathname.endsWith('/history') && request.method === 'GET') {<br>        const params = parsePathParams(url.pathname, '/api/applicant/:user_id/history');<br>        if (!params || !params.user_id) {<br>          return new Response(JSON.stringify({ error: 'User ID is required' }), {<br>            status: 400,<br>            headers: { 'Content-Type': 'application/json' },<br>          });<br>        }<br>        return handleJobHistoryGet(request, env, params);<br>      }<br>      if (url.pathname === '/api/applicant/job-rating' && request.method === 'POST') {<br>        return handleJobRatingPost(request, env);<br>      }<br>      if (url.pathname.startsWith('/api/applicant/') && url.pathname.endsWith('/job-ratings') && request.method === 'GET') {<br>        const params = parsePathParams(url.pathname, '/api/applicant/:user_id/job-ratings');<br>        if (!params || !params.user_id) {<br>          return new Response(JSON.stringify({ error: 'User ID is required' }), {<br>            status: 400,<br>            headers: { 'Content-Type': 'application/json' },<br>          });<br>        }<br>        return handleJobRatingsGet(request, env, params);<br>      }<br><br>` | `typescript<br>src/routes/api.ts, lines 335-358<br><br>    if (!params || !params.user_id) {<br>      return new Response(JSON.stringify({ error: 'User ID is required' }), {<br>        status: 400,<br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    }<br>    return handleJobHistoryGet(request, env, params);<br>  }<br>  if (url.pathname === '/api/applicant/job-rating' && request.method === 'POST') {<br>    return handleJobRatingPost(request, env);<br>  }<br>  if (url.pathname.startsWith('/api/applicant/') && url.pathname.endsWith('/job-ratings') && request.method === 'GET') {<br>    const params = parsePathParams(url.pathname, '/api/applicant/:user_id/job-ratings');<br>    if (!params || !params.user_id) {<br>      return new Response(JSON.stringify({ error: 'User ID is required' }), {<br>        status: 400,<br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    }<br>    return handleJobRatingsGet(request, env, params);<br>  }<br><br>  // Email management<br>  if (url.pathname === '/api/email/logs' && request.method === 'GET') {<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 1272-1284<br><br>      // Email Management Endpoints<br>      if (url.pathname === '/api/email/logs' && request.method === 'GET') {<br>        return handleEmailLogsGet(request, env);<br>      }<br>      if (url.pathname === '/api/email/configs' && request.method === 'GET') {<br>        return handleEmailConfigsGet(request, env);<br>      }<br>      if (url.pathname === '/api/email/configs' && request.method === 'PUT') {<br>        return handleEmailConfigsPut(request, env);<br>      }<br>      if (url.pathname === '/api/email/insights/send' && request.method === 'POST') {<br>        return handleEmailInsightsSend(request, env);<br>      }<br><br>` | `typescript<br>src/routes/api.ts, lines 359-372<br><br>    return handleEmailLogsGet(request, env);<br>  }<br>  if (url.pathname === '/api/email/configs' && request.method === 'GET') {<br>    return handleEmailConfigsGet(request, env);<br>  }<br>  if (url.pathname === '/api/email/configs' && request.method === 'PUT') {<br>    return handleEmailConfigsPut(request, env);<br>  }<br>  if (url.pathname === '/api/email/insights/send' && request.method === 'POST') {<br>    return handleEmailInsightsSend(request, env);<br>  }<br><br>  // Webhook utilities<br>  if (url.pathname === '/api/webhooks/test' && request.method === 'POST') {<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 1286-1306<br><br>      // Manual Crawl Endpoint<br>      if (url.pathname === '/api/crawl' && request.method === 'POST') {<br>        const body = await request.json() as { url: string; site_id?: string };<br>        if (!body.url) {<br>          return new Response(JSON.stringify({ error: 'URL is required' }), {<br>            status: 400,<br>            headers: { 'Content-Type': 'application/json' },<br>          });<br>        }<br><br>        const job = await crawlJob(env, body.url, body.site_id);<br>        if (job) {<br>          return new Response(JSON.stringify(job), {<br>            headers: { 'Content-Type': 'application/json' },<br>          });<br>        } else {<br>          return new Response(JSON.stringify({ error: 'Failed to crawl job' }), {<br>            status: 500,<br>            headers: { 'Content-Type': 'application/json' },<br>          });<br>        }<br>      }<br>` | `typescript<br>src/routes/crawl.ts, lines 5-21<br><br>  const body = await request.json() as { url: string; site_id?: string };<br>  if (!body.url) {<br>    return new Response(JSON.stringify({ error: 'URL is required' }), {<br>      status: 400,<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br><br>  const job = await crawlJob(env, body.url, body.site_id);<br>  if (job) {<br>    return new Response(JSON.stringify(job), {<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br><br>  return new Response(JSON.stringify({ error: 'Failed to crawl job' }), {<br>    status: 500,<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 1309-1413<br><br>      // AI Document Generation Routes<br>      if (url.pathname === '/api/cover-letter' && request.method === 'POST') {<br>        const body = (await request.json()) as CoverLetterRequestBody;<br>        if (!body.job_title || !body.company_name || !body.job_description_text || !body.candidate_career_summary) {<br>          return new Response(JSON.stringify({ error: 'Missing required fields in request body' }), {<br>            status: 400,<br>            headers: { 'Content-Type': 'application/json' },<br>          });<br>        }<br><br>        const coverLetterSchema = {<br>          type: 'object',<br>          properties: {<br>            salutation: {<br>              type: 'string',<br>              description:<br>                'A professional salutation, addressing the hiring manager by name if provided, otherwise using a general title like "Dear Hiring Manager,".',<br>            },<br>            opening_paragraph: {<br>              type: 'string',<br>              description:<br>                "A compelling opening paragraph that clearly states the position being applied for, where it was seen, and a powerful 1-2 sentence summary of the candidate's fitness for the role, creating immediate interest.",<br>            },<br>            body_paragraph_1: {<br>              type: 'string',<br>              description:<br>                "The first body paragraph. Connects the candidate's key experiences and skills directly to the most important requirements from the job description. Should highlight 1-2 specific, quantifiable achievements.",<br>            },<br>            body_paragraph_2: {<br>              type: 'string',<br>              description:<br>                "The second body paragraph. Focuses on the candidate's alignment with the company's mission, culture, or recent projects. Demonstrates genuine interest and shows how the candidate will add value to the team and company goals.",<br>            },<br>            closing_paragraph: {<br>              type: 'string',<br>              description:<br>                'A strong closing paragraph that reiterates interest in the role, expresses enthusiasm for the opportunity, and includes a clear call to action, such as requesting an interview to discuss their qualifications further.',<br>            },<br>          },<br>          required: ['salutation', 'opening_paragraph', 'body_paragraph_1', 'body_paragraph_2', 'closing_paragraph'],<br>        };<br><br>        const messages = [<br>          {<br>            role: 'system',<br>            content:<br>              'You are an expert career coach and professional cover letter writer. Your task is to generate the content for a compelling, tailored cover letter based on the provided job description and candidate summary. You must strictly adhere to the provided JSON schema for your response, filling in each field with high-quality, relevant content.',<br>          },<br>          {<br>            role: 'user',<br>            content: \`Please craft the content for a cover letter with the following details:\n\n- Job Title: ${body.job_title}\n- Company: ${body.company_name}\n- Hiring Manager: ${body.hiring_manager_name || 'Not specified'}\n\n--- Job Description ---\n${body.job_description_text}\n\n--- Candidate Career Summary ---\n${body.candidate_career_summary}\n\nGenerate the response following the required JSON schema.\`,<br>          },<br>        ];<br><br>        const inputs = { messages, guided_json: coverLetterSchema };<br>        const response = await env.AI.run('@cf/meta/llama-3.1-8b-instruct', inputs);<br>        return new Response(JSON.stringify(response), {<br>          headers: { 'Content-Type': 'application/json' },<br>        });<br>      }<br><br>      if (url.pathname === '/api/resume' && request.method === 'POST') {<br>        const body = (await request.json()) as ResumeRequestBody;<br>        if (!body.job_title || !body.company_name || !body.job_description_text || !body.candidate_career_summary) {<br>          return new Response(JSON.stringify({ error: 'Missing required fields in request body' }), {<br>            status: 400,<br>            headers: { 'Content-Type': 'application/json' },<br>          });<br>        }<br><br>        const resumeSchema = {<br>          type: 'object',<br>          properties: {<br>            summary: { type: 'string', description: 'Professional summary tailored to the job.' },<br>            experience_bullets: {<br>              type: 'array',<br>              description: 'Three concise bullet points highlighting relevant achievements.',<br>              items: { type: 'string' },<br>            },<br>            skills: {<br>              type: 'array',<br>              description: 'Key skills relevant to the job description.',<br>              items: { type: 'string' },<br>            },<br>          },<br>          required: ['summary', 'experience_bullets', 'skills'],<br>        };<br><br>        const messages = [<br>          {<br>            role: 'system',<br>            content:<br>              'You are an expert resume writer. Generate a resume summary, three experience bullet points, and a list of key skills tailored to the job description and candidate background. Use the provided JSON schema.',<br>          },<br>          {<br>            role: 'user',<br>            content: \`Generate resume content for the following details:\n\n- Job Title: ${body.job_title}\n- Company: ${body.company_name}\n\n--- Job Description ---\n${body.job_description_text}\n\n--- Candidate Career Summary ---\n${body.candidate_career_summary}\n\nFollow the JSON schema strictly.\`,<br>          },<br>        ];<br><br>        const inputs = { messages, guided_json: resumeSchema };<br>        const response = await env.AI.run('@cf/meta/llama-3.1-8b-instruct', inputs);<br>        return new Response(JSON.stringify(response), {<br>          headers: { 'Content-Type': 'application/json' },<br>        });<br>      }<br>` | `typescript<br>src/routes/ai-documents.ts, lines 25-117<br><br><br>interface ResumeContent {<br>  summary: string;<br>  experience_bullets: string[];<br>  skills: string[];<br>}<br><br>export async function handleCoverLetterPost(request: Request, env: Env): Promise<Response> {<br>  const body = await request.json() as CoverLetterRequestBody;<br>  if (!body.job_title || !body.company_name || !body.job_description_text || !body.candidate_career_summary) {<br>    return new Response(JSON.stringify({ error: 'Missing required fields in request body' }), {<br>      status: 400,<br>      headers: { 'Content-Type': 'application/json' },<br>    });<br>  }<br><br>  const coverLetterSchema = {<br>    type: 'object',<br>    properties: {<br>      salutation: {<br>        type: 'string',<br>        description: 'The salutation (e.g., Dear Hiring Manager,)',<br>      },<br>      opening_paragraph: {<br>        type: 'string',<br>        description: 'Compelling introduction tailored to the job and company',<br>      },<br>      body_paragraph_1: {<br>        type: 'string',<br>        description: 'First body paragraph with quantified achievements',<br>      },<br>      body_paragraph_2: {<br>        type: 'string',<br>        description: 'Second body paragraph highlighting company fit and motivation',<br>      },<br>      closing_paragraph: {<br>        type: 'string',<br>        description: 'Closing paragraph with call to action and sign-off',<br>      },<br>    },<br>    required: [<br>      'salutation',<br>      'opening_paragraph',<br>      'body_paragraph_1',<br>      'body_paragraph_2',<br>      'closing_paragraph',<br>    ],<br>  };<br><br>  const prompt = \`You are an expert career coach and copywriter specializing in crafting tailored cover letters.<br>  Generate a polished cover letter for the following candidate and job:<br><br>  Candidate Summary:<br>  ${body.candidate_career_summary}<br><br>  Job Title: ${body.job_title}<br>  Company: ${body.company_name}<br>  Hiring Manager: ${body.hiring_manager_name || 'Unknown'}<br><br>  Job Description:<br>  ${body.job_description_text}<br><br>  The cover letter should be concise, professional, and tailored to the job requirements.\`;<br><br>  const response = await env.AI.run('@cf/meta/llama-3.1-8b-instruct', {<br>    messages: [<br>      {<br>        role: 'system',<br>        content: 'You are an expert career coach and copywriter. Generate structured cover letters that are polished, professional, and tailored to the job description provided.',<br>      },<br>      {<br>        role: 'user',<br>        content: prompt,<br>      },<br>    ],<br>    response_format: {<br>      type: 'json_schema',<br>      json_schema: {<br>        name: 'cover_letter_response',<br>        schema: coverLetterSchema,<br>      },<br>    },<br>  });<br><br>  const structured = JSON.parse(response.response || '{}') as CoverLetterContent;<br><br>  return new Response(JSON.stringify(structured), {<br>    headers: { 'Content-Type': 'application/json' },<br>  });<br>}<br><br>export async function handleResumePost(request: Request, env: Env): Promise<Response> {<br>  const body = await request.json() as ResumeRequestBody;<br>  if (!body.job_title || !body.company_name || !body.job_description_text || !body.candidate_career_summary) {<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 1416-1421<br><br>      // Route not found<br>      return new Response(JSON.stringify({ error: 'Not Found' }), { <br>        status: 404,<br>        headers: { 'Content-Type': 'application/json' },<br>      });<br>    } catch (error: unknown) {<br>      console.error('Error processing request:', error);<br>` | `typescript<br>src/routes/api.ts, lines 373-378<br><br>    return handleWebhookTest(request, env);<br>  }<br><br>  // Manual crawl<br>  if (url.pathname === '/api/crawl' && request.method === 'POST') {<br>    return handleManualCrawlPost(request, env);<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 1422-1429<br><br>      console.error('Error processing request:', error);<br>      return new Response(<br>        JSON.stringify({ error: 'An internal server error occurred.' }),<br>        {<br>          status: 500,<br>          headers: { 'Content-Type': 'application/json' },<br>        },<br>      );<br>    }<br>` | `typescript<br>src/routes/api.ts, lines 1-378<br><br>(no equivalent centralized try/catch—errors bubble up without custom JSON response)` | ❌ Add a top-level try/catch in `handleApiRequest` to preserve the original JSON 500 response structure when unexpected errors occur.
| `typescript<br>src/index.ts (717d6af), lines 1433-1469<br><br>  /**<br>   * Email handler for Cloudflare Email Routing.<br>   * * Triggered by incoming emails configured in Cloudflare. This handler delegates processing<br>   * to \`handleEmailReceived\`, which is expected to parse the email and process it (e.g.,<br>   * ingest job leads or track application statuses).<br>   * * @param {ForwardableEmailMessage} message - The incoming email message object.<br>   * @param {Env} env - Worker environment bindings.<br>   * @param {ExecutionContext} ctx - Worker execution context.<br>   * @returns {Promise<void>}<br>   */<br>  async email(message: ForwardableEmailMessage, env: Env, ctx: ExecutionContext): Promise<void> {<br>    try {<br>      console.log(\`Email received from: ${message.from}, to: ${message.to}\`);<br>      <br>      // Create a mock Request object to pass the necessary email data to the HTTP handler<br>      // This is a common pattern to reuse HTTP-based routing/logic for email events.<br>      const request = new Request('http://localhost/email-ingestion', {<br>        method: 'POST',<br>        headers: message.headers,<br>        body: message.raw,<br>      });<br><br>      // Call your existing email processing logic<br>      const response = await handleEmailReceived(request, env);<br><br>      if (!response.ok) {<br>        // If processing fails, reject the email to notify the sender.<br>        const errorBody = await response.text();<br>        message.setReject(\`Email processing failed: ${errorBody}\`);<br>        console.error(\`Failed to process email: ${errorBody}\`);<br>      }<br>      <br>    } catch (error) {<br>      console.error('Error in email handler:', error);<br>      message.setReject('An internal error occurred during email processing.');<br>    }<br>  }, 	<br><br>` | `typescript<br>src/lib/email-event.ts, lines 4-21<br><br>export async function processEmailEvent(message: ForwardableEmailMessage, env: Env): Promise<void> {<br>  try {<br>    console.log(\`Email received from: ${message.from}, to: ${message.to}\`);<br><br>    const request = new Request('http://localhost/email-ingestion', {<br>      method: 'POST',<br>      headers: message.headers,<br>      body: message.raw,<br>    });<br><br>    const response = await handleEmailReceived(request, env);<br><br>    if (!response.ok) {<br>      const errorBody = await response.text();<br>      message.setReject(\`Email processing failed: ${errorBody}\`);<br>      console.error(\`Failed to process email: ${errorBody}\`);<br>    }<br>  } catch (error) {<br>    console.error('Error in email handler:', error);<br>` | ✅ |
| `typescript<br>src/index.ts (717d6af), lines 1471-1533<br><br>  /**<br>   * Scheduled handler for automated job monitoring and email insights.<br>   * * Runs on a configured cron schedule. Orchestrates two major autonomous tasks:<br>   * 1. **Daily Job Monitoring:** Triggers checks on existing jobs via \`runDailyJobMonitoring\`.<br>   * 2. **Email Insights:** Queries active \`email_configs\` and sends periodic job search reports.<br>   * * **Agent/Developer Notes:** This is the primary entry point for **autonomous execution** of<br>   * the monitoring and reporting agents within the \`codex\` ecosystem.<br>   * * @param {object} event - The scheduled event object.<br>   * @param {Env} env - Worker environment bindings.<br>   * @returns {Promise<void>}<br>   */<br>  async scheduled(event: any, env: Env): Promise<void> {<br>    console.log('Running scheduled job monitoring and email insights...');<br>    <br>    try {<br>      // Run daily job monitoring first (orchestrates JobMonitorWorkflow)<br>      console.log('Starting daily job monitoring...');<br>      const monitoringResult = await runDailyJobMonitoring(env);<br>      console.log('Daily monitoring completed:', monitoringResult);<br>      <br>      // Then run email insights<br>      console.log('Starting email insights...');<br>      <br>      // Get all enabled email configurations that are due to be sent<br>      const result = await env.DB.prepare(\`<br>        SELECT * FROM email_configs <br>        WHERE enabled = 1 <br>        AND (last_sent_at IS NULL OR <br>             datetime(last_sent_at, '+' || frequency_hours || ' hours') <= datetime('now'))<br>      \`).all();<br><br>      const configs = result.results || [];<br>      console.log(\`Found ${configs.length} email configs ready to send\`);<br><br>      for (const config of configs) {<br>        try {<br>          // Generate insights for this config<br>          const insights = await generateEmailInsights(env, config);<br>          <br>          // Send the email<br>          const emailSent = await sendInsightsEmail(insights, config, env);<br>          <br>          if (emailSent) {<br>            // Update last sent timestamp in the database<br>            await env.DB.prepare(\`<br>              UPDATE email_configs SET last_sent_at = CURRENT_TIMESTAMP WHERE id = ?<br>            \`).bind(config.id).run();<br>            <br>            console.log(\`Email insights sent successfully to ${config.recipient_email}\`);<br>          } else {<br>            console.error(\`Failed to send email insights to ${config.recipient_email}\`);<br>          }<br>        } catch (error) {<br>          console.error(\`Error processing email config ${config.id}:\`, error);<br>        }<br>      }<br>      <br>      console.log('Scheduled task completed successfully');<br>      <br>    } catch (error) {<br>      console.error('Error in scheduled task:', error);<br>    }<br>  },<br>` | `typescript<br>src/lib/scheduled.ts, lines 5-38<br><br>export async function handleScheduledEvent(env: Env): Promise<void> {<br>  console.log('Running scheduled job monitoring and email insights...');<br><br>  try {<br>    console.log('Starting daily job monitoring...');<br>    const monitoringResult = await runDailyJobMonitoring(env);<br>    console.log('Daily monitoring completed:', monitoringResult);<br><br>    console.log('Starting email insights...');<br><br>    const result = await env.DB.prepare(\`<br>      SELECT * FROM email_configs<br>      WHERE enabled = 1<br>      AND (last_sent_at IS NULL OR<br>           datetime(last_sent_at, '+' || frequency_hours || ' hours') <= datetime('now'))<br>    \`).all();<br><br>    const configs = result.results || [];<br>    console.log(\`Found ${configs.length} email configs ready to send\`);<br><br>    for (const config of configs) {<br>      try {<br>        const insights = await generateEmailInsights(env, config);<br>        const emailSent = await sendInsightsEmail(insights, config, env);<br><br>        if (emailSent) {<br>          await env.DB.prepare(\`<br>            UPDATE email_configs SET last_sent_at = CURRENT_TIMESTAMP WHERE id = ?<br>          \`).bind(config.id).run();<br><br>          console.log(\`Email insights sent successfully to ${config.recipient_email}\`);<br>        } else {<br>          console.error(\`Failed to send email insights to ${config.recipient_email}\`);<br>        }<br>      } catch (error) {<br>` | ✅ |
