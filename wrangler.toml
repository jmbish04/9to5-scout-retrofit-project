name = "9to5-scout" # 9to5-scout
main = "src/index.ts" # src/index.ts
compatibility_date = "2024-09-26"  # 2024-09-26
compatibility_flags = ["nodejs_compat"] # ["nodejs_compat"] -- needed for browser rendering

# Environment variables
[vars]
DEFAULT_MODEL_WEB_BROWSER = "@cf/meta/llama-3.1-8b-instruct"  # @cf/meta/llama-3.1-8b-instruct
DEFAULT_MODEL_REASONING = "@cf/openai/gpt-oss-120b" # @cf/openai/gpt-oss-120b
EMBEDDING_MODEL = "@cf/baai/bge-large-en-v1.5" # @cf/baai/bge-large-en-v1.5


# Secrets should be set using: wrangler secret bulk .dev.vars
# Required secrets:
# - WORKER_API_KEY (for ALL authentication to worker endpoints)
# - STEEL_API_KEY (for Steel scraper)
# - LINKEDIN_USERNAME (for LinkedIn scraping)
# - LINKEDIN_PASSWORD (for LinkedIn scraping)
# - BROWSER_RENDERING_TOKEN (for Cloudflare Browser Rendering REST API)
# - CLOUDFLARE_ACCOUNT_ID (for Cloudflare Browser Rendering REST API)
# - GITHUB_REPO (for Github repo)
# - BUCKET_BASE_URL (for R2 bucket base url)
# - NOTIFICATION_EMAIL_ADDRESS (for Notification email address)
# - EMAIL_ROUTING_DOMAIN (for Email routing domain)
# - LOCAL_SCRAPER_URL (for Local scraper url)
# - LOCAL_SCRAPER_API_KEY (for Local scraper api key)
# - PYTHON_SCRAPER_URL (for Python scraper Cloudflare Tunnel URL)
# - PYTHON_SCRAPER_API_KEY (for Python scraper API key)


# Observability Logs
[observability]
enabled = true

[observability.logs]
invocation_logs = true
head_sampling_rate = 1 # optional. default = 1.

# Browser Rendering binding
[browser]
binding = "MYBROWSER"

# D1 database for job scraper
[[d1_databases]]
binding = "DB"
database_name = "JOB_SCRAPER_DB"
database_id = "11092798-a3d9-44b8-be5f-1835c0027887"
preview_database_id = "11092798-a3d9-44b8-be5f-1835c0027887"  # Added missing preview_database_id
migrations_dir = "migrations"  # Added migrations configuration
migrations_table = "d1_migrations"

# Configuration KV namespace
[[kv_namespaces]]
binding = "KV"
id = "5e60b00818e9448b8f965af0fc96d39a"
preview_id = "5e60b00818e9448b8f965af0fc96d39a"  # Added missing preview_id

# Usage tracker
[[kv_namespaces]]
binding = "USAGE_TRACKER"
id = "d78887786a634316a921a869c2e406e8"
preview_id = "0900decc2f2043f4a5591eda43562065"

# R2 bucket for job scraper
[[r2_buckets]]
binding = "R2"
bucket_name = "job-scraper"
preview_bucket_name = "job-scraper-preview"

# Vectorize
[[vectorize]]
binding = "VECTORIZE_INDEX"
index_name = "jobs"

# AI
[ai]
binding = "AI"

# Configuration for sending emails from your worker
# This must be a verified sender address in your Cloudflare account
[[send_email]]
name = "EMAIL_SENDER"
destination_address = "justin@126colby.com"

# Service bindings (for communication with OTHER workers)
# Example: [[services]]
# binding = "AUTH_SERVICE"
# service = "auth-worker"

# Durable Objects
[durable_objects]
bindings = [
  { name = "SITE_CRAWLER", class_name = "SiteCrawler" },
  { name = "JOB_MONITOR", class_name = "JobMonitor" },
  { name = "SCRAPE_SOCKET", class_name = "ScrapeSocket" },
  { name = "GENERIC_AGENT", class_name = "GenericAgent" },
  { name = "EMAIL_PROCESSOR_AGENT", class_name = "EmailProcessorAgent" },
  { name = "JOB_MONITOR_AGENT", class_name = "JobMonitorAgent" },
  { name = "RESUME_OPTIMIZATION_AGENT", class_name = "ResumeOptimizationAgent" },
  { name = "COMPANY_INTELLIGENCE_AGENT", class_name = "CompanyIntelligenceAgent" },
  { name = "INTERVIEW_PREPARATION_AGENT", class_name = "InterviewPreparationAgent" },
  { name = "CAREER_COACH_AGENT", class_name = "CareerCoachAgent" }
]

# DiscoveryWorkflow
[[workflows]]
name = "discovery-workflow"
binding = "DISCOVERY_WORKFLOW"
class_name = "DiscoveryWorkflow"

# JobMonitorWorkflow
[[workflows]]
name = "job-monitor-workflow"
binding = "JOB_MONITOR_WORKFLOW"
class_name = "JobMonitorWorkflow"

# ChangeAnalysisWorkflow
[[workflows]]
name = "change-analysis-workflow"
binding = "CHANGE_ANALYSIS_WORKFLOW"
class_name = "ChangeAnalysisWorkflow"

# SiteCrawler and JobMonitor
[[migrations]]
tag = "v1"
new_sqlite_classes = ["SiteCrawler", "JobMonitor"]

# ScrapeSocket
[[migrations]]
tag = "v2"
new_sqlite_classes = ["ScrapeSocket"]  # Changed from new_classes to new_sqlite_classes

# GenericAgent for Cloudflare Agents SDK
[[migrations]]
tag = "v3"
new_sqlite_classes = ["GenericAgent"]

# EmailProcessorAgent for Cloudflare Agents SDK
[[migrations]]
tag = "v4"
new_sqlite_classes = ["EmailProcessorAgent"]

# New dedicated agents for Cloudflare Agents SDK
[[migrations]]
tag = "v5"
new_sqlite_classes = ["JobMonitorAgent", "ResumeOptimizationAgent", "CompanyIntelligenceAgent", "InterviewPreparationAgent"]

# Career Coach Agent for Cloudflare Agents SDK
[[migrations]]
tag = "v6"
new_sqlite_classes = ["CareerCoachAgent"]

# Triggers
[triggers]
crons = [
  "*/15 * * * *",  # every 15 minutes
  "0 6 * * *"      # daily 06:00
]

# Static assets for the limited admin operational frontend pages & html email templates
[assets]
directory = "./public" # ./public -- directory for static assets
binding = "ASSETS" # ASSETS -- for serving static assets
# exclude = [".DS_Store", "**/.DS_Store"] # THIS FIELD IS DEPRECATED, USE .assetsignore file instead; Exclude .DS_Store files from all directories
